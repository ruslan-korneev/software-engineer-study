# Horizontal vs Vertical Scaling

## Что такое масштабирование (Scaling)

**Масштабирование** — это способность системы справляться с возрастающей нагрузкой путём добавления ресурсов. Когда приложение растёт и количество пользователей увеличивается, серверы начинают испытывать нагрузку: CPU загружен на 100%, память заканчивается, время ответа растёт.

Существует два фундаментальных подхода к масштабированию:

```
┌─────────────────────────────────────────────────────────────────┐
│                    Способы масштабирования                      │
├────────────────────────────┬────────────────────────────────────┤
│   Вертикальное (Scale Up)  │   Горизонтальное (Scale Out)       │
│                            │                                    │
│   ┌──────────┐             │   ┌────┐ ┌────┐ ┌────┐ ┌────┐     │
│   │          │             │   │    │ │    │ │    │ │    │     │
│   │          │             │   │ S1 │ │ S2 │ │ S3 │ │ S4 │     │
│   │  Bigger  │             │   │    │ │    │ │    │ │    │     │
│   │  Server  │             │   └────┘ └────┘ └────┘ └────┘     │
│   │          │             │         Много серверов             │
│   └──────────┘             │                                    │
│   Мощнее сервер            │                                    │
└────────────────────────────┴────────────────────────────────────┘
```

---

## Вертикальное масштабирование (Scale Up)

### Определение

**Вертикальное масштабирование** — это увеличение мощности существующего сервера путём добавления ресурсов: больше CPU, RAM, дисков, более быстрые SSD.

```
Было:                          Стало:
┌─────────────────┐           ┌─────────────────┐
│   Server        │           │   Server        │
│                 │           │                 │
│   CPU: 4 cores  │    →      │   CPU: 32 cores │
│   RAM: 16 GB    │           │   RAM: 256 GB   │
│   SSD: 500 GB   │           │   SSD: 4 TB     │
└─────────────────┘           └─────────────────┘
```

### Плюсы вертикального масштабирования

| Преимущество | Описание |
|--------------|----------|
| **Простота** | Не нужно менять архитектуру приложения |
| **Нет распределённых проблем** | Отсутствуют проблемы синхронизации, сетевые задержки между узлами |
| **Консистентность данных** | Все данные на одной машине — не нужны распределённые транзакции |
| **Меньше операционных затрат** | Один сервер проще администрировать |
| **Любое приложение** | Работает даже со stateful приложениями без изменений |

### Минусы вертикального масштабирования

| Недостаток | Описание |
|------------|----------|
| **Физический предел** | Существует максимальная конфигурация сервера |
| **Single Point of Failure** | Если сервер падает — всё падает |
| **Дороговизна** | High-end серверы экспоненциально дороже |
| **Downtime при апгрейде** | Замена железа требует остановки сервера |
| **Diminishing returns** | Удвоение ресурсов не даёт удвоения производительности |

### Ограничения

```
Стоимость vs Производительность

Цена │
     │                              ╭──── Технический предел
     │                         ╭───╯
     │                    ╭───╯
     │               ╭───╯
     │          ╭───╯
     │     ╭───╯
     │ ───╯
     └─────────────────────────────────── Производительность

На определённом уровне дальнейшее увеличение ресурсов:
- Становится непропорционально дорогим
- Технически невозможным (предел CPU, RAM на материнской плате)
```

**Примеры ограничений:**
- Максимум ~100+ ядер CPU на один сервер
- Максимум ~12 TB RAM (для high-end серверов)
- Максимальная пропускная способность одного NIC
- Ограничения шины PCI Express

---

## Горизонтальное масштабирование (Scale Out)

### Определение

**Горизонтальное масштабирование** — это добавление новых серверов (узлов) в кластер для распределения нагрузки.

```
Было:                          Стало:
┌─────────────────┐           ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│                 │           │     │ │     │ │     │ │     │
│   Server        │    →      │ S1  │ │ S2  │ │ S3  │ │ S4  │
│                 │           │     │ │     │ │     │ │     │
└─────────────────┘           └─────┘ └─────┘ └─────┘ └─────┘
                                      │
                              ┌───────┴───────┐
                              │ Load Balancer │
                              └───────────────┘
```

### Плюсы горизонтального масштабирования

| Преимущество | Описание |
|--------------|----------|
| **Практически неограниченно** | Можно добавлять сотни и тысячи серверов |
| **Отказоустойчивость** | Падение одного узла не убивает систему |
| **Гибкость** | Можно добавлять/убирать узлы по необходимости |
| **Экономичность** | Много дешёвых серверов дешевле одного супер-мощного |
| **Географическое распределение** | Серверы могут быть в разных дата-центрах |
| **Zero-downtime scaling** | Добавление узлов без остановки системы |

### Минусы горизонтального масштабирования

| Недостаток | Описание |
|------------|----------|
| **Сложность архитектуры** | Требуется distributed systems знания |
| **Синхронизация данных** | Консистентность между узлами — сложная задача |
| **Сетевые задержки** | Коммуникация между узлами добавляет latency |
| **Stateless требование** | Приложение должно быть stateless |
| **Операционная сложность** | Больше серверов — больше точек администрирования |
| **Сессии и state** | Нужны внешние хранилища (Redis, DB) для состояния |

### Требования к приложению (Stateless)

Для горизонтального масштабирования приложение **должно быть stateless** — не хранить состояние в памяти процесса.

```
❌ Stateful приложение (не масштабируется горизонтально):

┌─────────────────────────────────────────┐
│ Server 1                                │
│ ┌─────────────────────────────────────┐ │
│ │ Application Memory                  │ │
│ │ - User sessions                     │ │
│ │ - Shopping cart data                │ │
│ │ - Cached user preferences           │ │
│ └─────────────────────────────────────┘ │
└─────────────────────────────────────────┘

Проблема: если следующий запрос попадёт на Server 2,
там нет данных сессии пользователя!
```

```
✅ Stateless приложение (масштабируется):

┌────────────────────────────────────────────────────────────┐
│                      Load Balancer                          │
└────────────────────────────────────────────────────────────┘
         │                    │                    │
         ▼                    ▼                    ▼
   ┌──────────┐         ┌──────────┐         ┌──────────┐
   │ Server 1 │         │ Server 2 │         │ Server 3 │
   │ (no      │         │ (no      │         │ (no      │
   │  state)  │         │  state)  │         │  state)  │
   └──────────┘         └──────────┘         └──────────┘
         │                    │                    │
         └────────────────────┼────────────────────┘
                              ▼
                    ┌──────────────────┐
                    │     Redis        │  ← Сессии
                    │ (Session Store)  │
                    └──────────────────┘
                              │
                    ┌──────────────────┐
                    │    Database      │  ← Данные
                    └──────────────────┘

Любой сервер может обработать любой запрос!
```

**Правила stateless приложения:**

1. **Сессии** — хранить во внешнем хранилище (Redis, Memcached, DB)
2. **Файлы** — использовать распределённое хранилище (S3, GCS)
3. **Кэш** — использовать распределённый кэш (Redis Cluster)
4. **Конфигурация** — передавать через environment variables

```python
# ❌ Плохо: state в памяти процесса
class ShoppingCart:
    carts = {}  # Хранится в памяти этого процесса!

    def add_item(self, user_id, item):
        if user_id not in self.carts:
            self.carts[user_id] = []
        self.carts[user_id].append(item)

# ✅ Хорошо: state во внешнем хранилище
import redis

class ShoppingCart:
    def __init__(self):
        self.redis = redis.Redis(host='redis-cluster')

    def add_item(self, user_id, item):
        key = f"cart:{user_id}"
        self.redis.lpush(key, json.dumps(item))
```

---

## Сравнительная таблица подходов

| Критерий | Вертикальное (Scale Up) | Горизонтальное (Scale Out) |
|----------|------------------------|---------------------------|
| **Способ** | Увеличение мощности сервера | Добавление серверов |
| **Сложность** | Низкая | Высокая |
| **Предел масштабирования** | Ограничен аппаратно | Практически неограничен |
| **Стоимость** | Экспоненциально растёт | Линейно растёт |
| **Отказоустойчивость** | Single point of failure | Высокая (redundancy) |
| **Downtime при изменении** | Требуется | Не требуется |
| **Изменение кода** | Не требуется | Часто требуется (stateless) |
| **Консистентность данных** | Простая (локальные данные) | Сложная (распределённые данные) |
| **Сетевая сложность** | Отсутствует | Присутствует (latency, partitions) |
| **Типичное применение** | БД, legacy apps | Web servers, microservices |

---

## Когда использовать какой подход

### Используйте вертикальное масштабирование когда:

```
┌─────────────────────────────────────────────────────────────┐
│ ✓ Начальная стадия проекта (MVP, стартап)                   │
│ ✓ Приложение сложно сделать stateless                      │
│ ✓ База данных с ACID требованиями                          │
│ ✓ Legacy приложение без возможности рефакторинга           │
│ ✓ Нагрузка укладывается в возможности одного сервера       │
│ ✓ Небольшая команда без DevOps экспертизы                  │
│ ✓ Стоимость downtime ниже стоимости распределённой системы │
└─────────────────────────────────────────────────────────────┘
```

### Используйте горизонтальное масштабирование когда:

```
┌─────────────────────────────────────────────────────────────┐
│ ✓ Высокая нагрузка, превышающая возможности одного сервера │
│ ✓ Требуется высокая доступность (99.9%+)                   │
│ ✓ Нагрузка сильно варьируется (spiky traffic)              │
│ ✓ Географически распределённые пользователи                │
│ ✓ Микросервисная архитектура                               │
│ ✓ Cloud-native приложения                                  │
│ ✓ Stateless workloads (API servers, workers)               │
└─────────────────────────────────────────────────────────────┘
```

### Гибридный подход

На практике часто используется **комбинация обоих подходов**:

```
                    ┌──────────────────┐
                    │   Load Balancer  │
                    └────────┬─────────┘
           ┌─────────────────┼─────────────────┐
           ▼                 ▼                 ▼
     ┌───────────┐     ┌───────────┐     ┌───────────┐
     │  Web 1    │     │  Web 2    │     │  Web 3    │  ← Горизонтальное
     │ (8 CPU)   │     │ (8 CPU)   │     │ (8 CPU)   │
     └───────────┘     └───────────┘     └───────────┘
           │                 │                 │
           └─────────────────┼─────────────────┘
                             ▼
                    ┌──────────────────┐
                    │    Database      │  ← Вертикальное
                    │   (64 CPU,       │     (мощный сервер)
                    │    512 GB RAM)   │
                    └──────────────────┘
```

---

## Масштабирование различных компонентов

### Web Servers

Web-серверы **идеально подходят для горизонтального масштабирования**:

```
                         ┌─────────────────────┐
                         │    DNS (Round      │
                         │    Robin / GeoDNS) │
                         └──────────┬──────────┘
                                    │
              ┌─────────────────────┼─────────────────────┐
              ▼                     ▼                     ▼
     ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐
     │  Load Balancer  │   │  Load Balancer  │   │  Load Balancer  │
     │   (Region 1)    │   │   (Region 2)    │   │   (Region 3)    │
     └────────┬────────┘   └────────┬────────┘   └────────┬────────┘
              │                     │                     │
     ┌────────┼────────┐   ┌────────┼────────┐   ┌────────┼────────┐
     ▼        ▼        ▼   ▼        ▼        ▼   ▼        ▼        ▼
   ┌───┐   ┌───┐   ┌───┐ ┌───┐   ┌───┐   ┌───┐ ┌───┐   ┌───┐   ┌───┐
   │W1 │   │W2 │   │W3 │ │W1 │   │W2 │   │W3 │ │W1 │   │W2 │   │W3 │
   └───┘   └───┘   └───┘ └───┘   └───┘   └───┘ └───┘   └───┘   └───┘
```

**Стратегии балансировки:**
- **Round Robin** — запросы по кругу
- **Least Connections** — на сервер с минимумом подключений
- **IP Hash** — по хэшу IP клиента (sticky sessions)
- **Weighted** — с учётом мощности серверов

### Databases

Масштабирование баз данных — **самая сложная задача**:

#### Вертикальное масштабирование БД

```
Простой путь для реляционных БД:

┌─────────────────────────────────────┐
│          PostgreSQL                 │
│                                     │
│  CPU: 4 → 32 → 64 → 128 cores       │
│  RAM: 32 → 128 → 512 GB → 1 TB      │
│  Storage: SSD → NVMe RAID           │
│                                     │
│  + Read replicas для чтения         │
└─────────────────────────────────────┘
```

#### Горизонтальное масштабирование БД

```
Стратегия 1: Read Replicas (Master-Slave)
─────────────────────────────────────────

         Writes ──────▶ ┌────────────────┐
                        │    Master      │
                        │   (Primary)    │
                        └───────┬────────┘
                                │ Replication
              ┌─────────────────┼─────────────────┐
              ▼                 ▼                 ▼
     ┌──────────────┐  ┌──────────────┐  ┌──────────────┐
     │   Replica 1  │  │   Replica 2  │  │   Replica 3  │
     └──────────────┘  └──────────────┘  └──────────────┘
              ▲                 ▲                 ▲
              └─────────────────┴─────────────────┘
                              Reads


Стратегия 2: Sharding (партиционирование данных)
────────────────────────────────────────────────

                    ┌─────────────────────────┐
                    │    Routing Layer        │
                    │    (shard key: user_id) │
                    └───────────┬─────────────┘
                                │
        ┌───────────────────────┼───────────────────────┐
        │                       │                       │
        ▼                       ▼                       ▼
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│   Shard 1     │       │   Shard 2     │       │   Shard 3     │
│ users: A-H    │       │ users: I-P    │       │ users: Q-Z    │
└───────────────┘       └───────────────┘       └───────────────┘
```

**Сравнение стратегий для БД:**

| Стратегия | Сложность | Масштабирует | Trade-offs |
|-----------|-----------|--------------|------------|
| Vertical | Низкая | Reads + Writes | Предел сервера |
| Read Replicas | Средняя | Только Reads | Replication lag |
| Sharding | Высокая | Reads + Writes | Cross-shard queries сложны |
| NewSQL (CockroachDB) | Средняя | Reads + Writes | Learning curve |

### Caches

Кэши масштабируются **горизонтально через кластеризацию**:

```
Redis Cluster
─────────────

                    ┌──────────────────┐
                    │    Application   │
                    └────────┬─────────┘
                             │
              ┌──────────────┼──────────────┐
              ▼              ▼              ▼
         ┌─────────┐    ┌─────────┐    ┌─────────┐
         │  Redis  │    │  Redis  │    │  Redis  │
         │  Node 1 │    │  Node 2 │    │  Node 3 │
         │ (slots  │    │ (slots  │    │ (slots  │
         │ 0-5460) │    │ 5461-   │    │ 10923-  │
         │         │    │ 10922)  │    │ 16383)  │
         └─────────┘    └─────────┘    └─────────┘
              │              │              │
              ▼              ▼              ▼
         ┌─────────┐    ┌─────────┐    ┌─────────┐
         │ Replica │    │ Replica │    │ Replica │
         └─────────┘    └─────────┘    └─────────┘

Данные распределяются по hash slots (16384 слота)
```

**Consistent Hashing** — алгоритм, минимизирующий перераспределение ключей при добавлении/удалении узлов:

```
            Node A
              │
              ▼
    ┌─────────────────────┐
    │                     │
Node D                    Node B
    │                     │
    └──────────┬──────────┘
               │
            Node C

При добавлении Node E:
- Перераспределяются только ключи между соседями
- Не нужно rehash всех ключей
```

---

## Auto-scaling

**Auto-scaling** — автоматическое добавление/удаление инстансов на основе метрик.

### Типы Auto-scaling

```
1. Reactive (по событию)
─────────────────────────
   Метрика превысила порог → добавляем инстансы

   CPU > 70% ──▶ Scale Up (+2 instances)
   CPU < 30% ──▶ Scale Down (-1 instance)


2. Scheduled (по расписанию)
────────────────────────────
   Известные паттерны нагрузки

   ┌─────────────────────────────────────────┐
   │ Нагрузка                                │
   │     ╭───╮                   ╭───╮       │
   │    ╱     ╲                 ╱     ╲      │
   │   ╱       ╲               ╱       ╲     │
   │──╯         ╰─────────────╯         ╰─── │
   │  9:00    18:00          9:00    18:00   │
   │   Пн       Пн            Вт       Вт    │
   └─────────────────────────────────────────┘

   Cron: "0 8 * * 1-5" → Scale to 10 instances
   Cron: "0 20 * * 1-5" → Scale to 3 instances


3. Predictive (предиктивное)
────────────────────────────
   ML-модели предсказывают нагрузку

   Historical Data ──▶ ML Model ──▶ Predicted Load ──▶ Pre-scale
```

### AWS Auto Scaling Group (пример конфигурации)

```yaml
# AWS Auto Scaling Policy
AutoScalingGroup:
  MinSize: 2
  MaxSize: 20
  DesiredCapacity: 4

  TargetTrackingConfiguration:
    TargetValue: 70.0
    PredefinedMetricSpecification:
      PredefinedMetricType: ASGAverageCPUUtilization

  # Cooldown между scaling actions
  Cooldown: 300  # 5 минут

  # Step Scaling
  StepAdjustments:
    - MetricIntervalLowerBound: 0
      MetricIntervalUpperBound: 20
      ScalingAdjustment: 1
    - MetricIntervalLowerBound: 20
      ScalingAdjustment: 2
```

### Kubernetes Horizontal Pod Autoscaler

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 3
  maxReplicas: 50
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    # Custom metrics (например, requests per second)
    - type: Pods
      pods:
        metric:
          name: http_requests_per_second
        target:
          type: AverageValue
          averageValue: "1000"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
```

### Best Practices для Auto-scaling

```
┌────────────────────────────────────────────────────────────────┐
│ 1. Установите адекватные cooldown периоды                      │
│    - Слишком короткие → thrashing (постоянный scale up/down)   │
│    - Слишком длинные → медленная реакция на нагрузку           │
│                                                                │
│ 2. Используйте несколько метрик                                │
│    - CPU + Memory + Custom metrics (RPS, latency)              │
│                                                                │
│ 3. Тестируйте auto-scaling                                     │
│    - Load testing для проверки поведения                       │
│    - Chaos engineering для проверки отказоустойчивости         │
│                                                                │
│ 4. Мониторинг и алерты                                         │
│    - Алерты когда достигнут max capacity                       │
│    - Аномалии в scaling behaviour                              │
│                                                                │
│ 5. Graceful shutdown                                           │
│    - Дайте время на завершение текущих запросов                │
│    - Drain connections перед termination                       │
└────────────────────────────────────────────────────────────────┘
```

---

## Примеры из реальных систем

### Netflix

```
Архитектура Netflix:
────────────────────

┌─────────────────────────────────────────────────────────────────┐
│                        AWS Cloud                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │                    Zuul (API Gateway)                    │   │
│   │              Горизонтально масштабируется               │   │
│   └─────────────────────────────────────────────────────────┘   │
│                              │                                   │
│   ┌──────────────────────────┴──────────────────────────┐       │
│   │                                                      │       │
│   ▼                          ▼                          ▼       │
│ ┌───────────┐          ┌───────────┐          ┌───────────┐     │
│ │ Service A │          │ Service B │          │ Service C │     │
│ │ (1000+    │          │ (500+     │          │ (200+     │     │
│ │ instances)│          │ instances)│          │ instances)│     │
│ └───────────┘          └───────────┘          └───────────┘     │
│                                                                  │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │                  Cassandra Cluster                       │   │
│   │          (Hundreds of nodes, 10+ PB data)               │   │
│   │              Горизонтальное масштабирование              │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                  │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │                    EVCache (Memcached)                   │   │
│   │            Распределённый кэш на тысячах узлов          │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘

Ключевые решения Netflix:
- Микросервисы: 700+ сервисов
- Auto-scaling: Titus (контейнерная платформа)
- Chaos Engineering: Chaos Monkey для тестирования отказоустойчивости
```

### Instagram

```
Instagram изначально использовал вертикальное масштабирование,
затем перешёл к гибридному подходу:

Web Tier (Горизонтальное):
──────────────────────────
- Django приложение на сотнях серверов
- Stateless design
- Load balancing через HAProxy

Database Tier (Гибридное):
──────────────────────────
PostgreSQL:
├── Мощные primary серверы (вертикальное)
├── Read replicas (горизонтальное для reads)
└── Sharding по user_id (горизонтальное)

Cassandra (Горизонтальное):
├── Feed storage
└── Direct messaging

Cache Tier (Горизонтальное):
────────────────────────────
- Memcached cluster
- Redis для сессий и real-time features
```

### Uber

```
Uber использует комбинацию подходов:

┌─────────────────────────────────────────────────────────────────┐
│                     Dispatch System                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                   Ringpop (Gossip)                         │  │
│  │     Распределённое кольцо для consistent hashing          │  │
│  └───────────────────────────────────────────────────────────┘  │
│                              │                                   │
│         ┌────────────────────┼────────────────────┐             │
│         ▼                    ▼                    ▼             │
│   ┌───────────┐        ┌───────────┐        ┌───────────┐       │
│   │ Dispatch  │        │ Dispatch  │        │ Dispatch  │       │
│   │ Service   │        │ Service   │        │ Service   │       │
│   │ (Geo: SF) │        │ (Geo: NY) │        │ (Geo: LA) │       │
│   └───────────┘        └───────────┘        └───────────┘       │
│                                                                  │
│  База данных: Schemaless (MySQL sharding layer)                 │
│  - Партиционирование по городам и времени                      │
│  - Тысячи MySQL инстансов                                       │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘

Масштабирование Uber:
- Real-time matching: горизонтально в каждом городе
- Historical data: sharded MySQL
- Maps data: specialized distributed storage
```

### Stack Overflow

```
Stack Overflow — пример успешного ВЕРТИКАЛЬНОГО масштабирования:

Один из самых посещаемых сайтов (Top 50) работает на:
- 9 Web серверов
- 4 SQL серверов
- 2 Redis серверов
- 2 Elasticsearch серверов

┌─────────────────────────────────────────────────────────────────┐
│                     Stack Overflow                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │              HAProxy (Load Balancer)                     │   │
│   └─────────────────────────────────────────────────────────┘   │
│                              │                                   │
│         ┌────────────────────┼────────────────────┐             │
│         ▼                    ▼                    ▼             │
│   ┌───────────┐        ┌───────────┐        ┌───────────┐       │
│   │  IIS Web  │        │  IIS Web  │        │  ... x9   │       │
│   │  256 GB   │        │  256 GB   │        │           │       │
│   │  RAM each │        │  RAM each │        │           │       │
│   └───────────┘        └───────────┘        └───────────┘       │
│                              │                                   │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │                  SQL Server Cluster                      │   │
│   │              (1.5 TB RAM, 384 cores total)              │   │
│   │            Мощные серверы + репликация                  │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                  │
│   Почему это работает:                                          │
│   - Агрессивное кэширование (Redis)                             │
│   - Оптимизированные SQL запросы                                │
│   - Минимальный overhead (монолит на C#)                        │
│   - 1.3 миллиарда page views/месяц на этом железе              │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘

Вывод: Вертикальное масштабирование + правильная оптимизация
может справиться с огромной нагрузкой!
```

---

## Резюме

```
┌─────────────────────────────────────────────────────────────────┐
│                    Ключевые выводы                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  1. Вертикальное масштабирование — проще, но имеет предел       │
│                                                                  │
│  2. Горизонтальное — сложнее, но практически неограниченно      │
│                                                                  │
│  3. В реальности используют ГИБРИДНЫЙ подход:                   │
│     - Web servers → горизонтально                               │
│     - Databases → сначала вертикально, затем sharding          │
│     - Caches → горизонтально с consistent hashing              │
│                                                                  │
│  4. Stateless дизайн — ключ к горизонтальному масштабированию  │
│                                                                  │
│  5. Auto-scaling позволяет адаптироваться к нагрузке            │
│     автоматически (но требует тщательной настройки)             │
│                                                                  │
│  6. "Premature scaling is the root of all evil"                │
│     Не масштабируйте раньше времени — сначала оптимизируйте!   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Дополнительные ресурсы

- [Designing Data-Intensive Applications](https://dataintensive.net/) — книга Martin Kleppmann
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)
- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)
- [High Scalability Blog](http://highscalability.com/)
