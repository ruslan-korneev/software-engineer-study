# Основы сложности алгоритмов

## Зачем нужен анализ сложности?

Когда мы пишем алгоритм, нам важно понимать:
1. **Насколько быстро он работает?** (временная сложность)
2. **Сколько памяти он использует?** (пространственная сложность)

Анализ сложности позволяет сравнивать алгоритмы и выбирать наиболее эффективный для конкретной задачи.

## Big O нотация

**Big O** (О-большое) — это математическая нотация для описания верхней границы роста функции. В контексте алгоритмов она показывает, как растёт время выполнения или потребление памяти при увеличении размера входных данных.

### Основные правила Big O:

1. **Игнорируем константы**: O(2n) → O(n)
2. **Берём доминирующий член**: O(n² + n) → O(n²)
3. **Рассматриваем худший случай** (обычно)

### Примеры упрощения:

| Выражение | Big O |
|-----------|-------|
| O(5n + 3) | O(n) |
| O(n² + 100n + 50) | O(n²) |
| O(n/2) | O(n) |
| O(1000) | O(1) |
| O(3n³ + 2n² + n) | O(n³) |

## Временная сложность

Временная сложность показывает, как количество операций зависит от размера входных данных (n).

### Основные классы сложности (от лучшего к худшему):

| Сложность | Название | Пример |
|-----------|----------|--------|
| O(1) | Константная | Доступ к элементу массива |
| O(log n) | Логарифмическая | Бинарный поиск |
| O(n) | Линейная | Линейный поиск |
| O(n log n) | Линейно-логарифмическая | Быстрая сортировка |
| O(n²) | Квадратичная | Сортировка пузырьком |
| O(n³) | Кубическая | Умножение матриц (наивное) |
| O(2ⁿ) | Экспоненциальная | Рекурсивный Фибоначчи |
| O(n!) | Факториальная | Перебор всех перестановок |

## O(1) — Константная сложность

Время выполнения не зависит от размера входных данных.

```python
def get_first_element(arr):
    """
    O(1) - всегда одна операция,
    независимо от размера массива
    """
    return arr[0]


def check_even(number):
    """
    O(1) - одна операция деления
    """
    return number % 2 == 0


def swap(a, b):
    """
    O(1) - фиксированное число операций
    """
    temp = a
    a = b
    b = temp
    return a, b


# Примеры
arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # 10 элементов
arr_big = list(range(1000000))         # 1 000 000 элементов

# Обе операции выполняются одинаково быстро!
get_first_element(arr)      # O(1)
get_first_element(arr_big)  # O(1)
```

## O(log n) — Логарифмическая сложность

Время выполнения растёт логарифмически. Каждый шаг уменьшает задачу вдвое.

```python
def binary_search(arr, target):
    """
    O(log n) - на каждом шаге отбрасываем половину массива

    Для 1000 элементов: ~10 шагов (2^10 = 1024)
    Для 1000000 элементов: ~20 шагов (2^20 = 1048576)
    """
    left = 0
    right = len(arr) - 1

    while left <= right:
        mid = (left + right) // 2

        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1

    return -1


# Примеры использования
sorted_arr = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
print(binary_search(sorted_arr, 7))   # 3
print(binary_search(sorted_arr, 10))  # -1
```

### Понимание логарифма:

| n (размер) | log₂(n) (шагов) |
|------------|-----------------|
| 8 | 3 |
| 16 | 4 |
| 1,024 | 10 |
| 1,048,576 | 20 |
| 1,073,741,824 | 30 |

## O(n) — Линейная сложность

Время выполнения растёт пропорционально размеру входных данных.

```python
def linear_search(arr, target):
    """
    O(n) - в худшем случае проверяем все элементы
    """
    for i in range(len(arr)):
        if arr[i] == target:
            return i
    return -1


def find_max(arr):
    """
    O(n) - проходим по всем элементам один раз
    """
    max_val = arr[0]
    for num in arr:
        if num > max_val:
            max_val = num
    return max_val


def calculate_sum(arr):
    """
    O(n) - суммируем все элементы
    """
    total = 0
    for num in arr:
        total += num
    return total


def print_all(arr):
    """
    O(n) - выводим каждый элемент
    """
    for item in arr:
        print(item)


# Пример: время удваивается при удвоении массива
small = [1, 2, 3, 4, 5]           # 5 операций
medium = list(range(100))          # 100 операций
large = list(range(1000))          # 1000 операций
```

## O(n²) — Квадратичная сложность

Время выполнения растёт как квадрат размера данных. Обычно возникает при вложенных циклах.

```python
def bubble_sort(arr):
    """
    O(n²) - два вложенных цикла
    """
    n = len(arr)
    for i in range(n):
        for j in range(n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
    return arr


def print_pairs(arr):
    """
    O(n²) - выводим все пары элементов
    """
    for i in range(len(arr)):
        for j in range(len(arr)):
            print(f"({arr[i]}, {arr[j]})")


def has_duplicates(arr):
    """
    O(n²) - сравниваем каждый элемент с каждым
    (неоптимальный способ!)
    """
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            if arr[i] == arr[j]:
                return True
    return False


# Сравнение скорости
# n = 10:    10² = 100 операций
# n = 100:   100² = 10,000 операций
# n = 1000:  1000² = 1,000,000 операций
```

## O(n log n) — Линейно-логарифмическая сложность

Типична для эффективных алгоритмов сортировки.

```python
def merge_sort(arr):
    """
    O(n log n) - разделяй и властвуй
    """
    if len(arr) <= 1:
        return arr

    mid = len(arr) // 2
    left = merge_sort(arr[:mid])   # log n уровней
    right = merge_sort(arr[mid:])  # рекурсии

    return merge(left, right)      # n операций слияния


def merge(left, right):
    """Слияние двух отсортированных массивов"""
    result = []
    i = j = 0

    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1

    result.extend(left[i:])
    result.extend(right[j:])
    return result


# Встроенная сортировка Python использует Timsort - O(n log n)
arr = [64, 34, 25, 12, 22, 11, 90]
sorted_arr = sorted(arr)  # O(n log n)
```

## Сравнение сложностей на практике

Допустим, одна операция занимает 1 микросекунду (1 μs = 0.000001 секунды):

| n | O(1) | O(log n) | O(n) | O(n log n) | O(n²) | O(2ⁿ) |
|---|------|----------|------|------------|-------|-------|
| 10 | 1 μs | 3 μs | 10 μs | 33 μs | 100 μs | 1 ms |
| 100 | 1 μs | 7 μs | 100 μs | 664 μs | 10 ms | 10²² лет |
| 1,000 | 1 μs | 10 μs | 1 ms | 10 ms | 1 сек | ∞ |
| 10,000 | 1 μs | 13 μs | 10 ms | 132 ms | 1.7 мин | ∞ |
| 100,000 | 1 μs | 17 μs | 100 ms | 1.7 сек | 2.8 часа | ∞ |
| 1,000,000 | 1 μs | 20 μs | 1 сек | 20 сек | 11.5 дней | ∞ |

## Пространственная сложность

Показывает, сколько дополнительной памяти требует алгоритм.

```python
def sum_array(arr):
    """
    Пространственная сложность: O(1)
    Используем только переменную total
    """
    total = 0
    for num in arr:
        total += num
    return total


def copy_array(arr):
    """
    Пространственная сложность: O(n)
    Создаём копию массива того же размера
    """
    new_arr = []
    for num in arr:
        new_arr.append(num)
    return new_arr


def create_matrix(n):
    """
    Пространственная сложность: O(n²)
    Создаём матрицу n x n
    """
    matrix = []
    for i in range(n):
        row = [0] * n
        matrix.append(row)
    return matrix
```

## Анализ алгоритмов: примеры

### Пример 1: Поиск элемента

```python
# O(n) - линейный поиск
def find_in_list(lst, target):
    for item in lst:
        if item == target:
            return True
    return False

# O(1) - поиск в множестве (хеш-таблица)
def find_in_set(s, target):
    return target in s

# Практическое применение
data_list = list(range(1000000))
data_set = set(range(1000000))

# find_in_list займёт ~0.1 сек для поиска последнего элемента
# find_in_set займёт ~0.000001 сек для любого элемента
```

### Пример 2: Проверка на дубликаты

```python
# O(n²) - неэффективный способ
def has_duplicates_slow(arr):
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            if arr[i] == arr[j]:
                return True
    return False

# O(n) - эффективный способ с использованием set
def has_duplicates_fast(arr):
    seen = set()
    for item in arr:
        if item in seen:
            return True
        seen.add(item)
    return False

# Или ещё проще:
def has_duplicates_pythonic(arr):
    return len(arr) != len(set(arr))
```

### Пример 3: Числа Фибоначчи

```python
# O(2ⁿ) - наивная рекурсия (очень медленно!)
def fib_slow(n):
    if n <= 1:
        return n
    return fib_slow(n - 1) + fib_slow(n - 2)

# O(n) - с мемоизацией
def fib_memo(n, memo={}):
    if n in memo:
        return memo[n]
    if n <= 1:
        return n
    memo[n] = fib_memo(n - 1, memo) + fib_memo(n - 2, memo)
    return memo[n]

# O(n) - итеративный способ
def fib_fast(n):
    if n <= 1:
        return n
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b

# fib_slow(40) займёт ~минуту
# fib_fast(40) займёт микросекунды
```

## Как определять сложность?

### Правила анализа:

1. **Простые операции** → O(1)
2. **Один цикл по n элементам** → O(n)
3. **Вложенные циклы** → перемножаем (O(n) × O(n) = O(n²))
4. **Последовательные блоки** → берём максимум
5. **Рекурсия, делящая задачу пополам** → O(log n)

### Примеры анализа:

```python
# O(1) - константа
x = 5 + 3

# O(n) - один цикл
for i in range(n):
    print(i)

# O(n²) - вложенные циклы
for i in range(n):
    for j in range(n):
        print(i, j)

# O(n + m) - два независимых цикла
for i in range(n):
    print(i)
for j in range(m):
    print(j)

# O(n * m) - вложенные циклы с разными переменными
for i in range(n):
    for j in range(m):
        print(i, j)
```

## Практические советы

1. **Избегайте вложенных циклов**, когда это возможно
2. **Используйте правильные структуры данных** (set вместо list для поиска)
3. **Предпочитайте O(n log n) сортировки** встроенным sorted()
4. **Кэшируйте результаты** (мемоизация) для повторяющихся вычислений
5. **Анализируйте худший случай**, но помните о среднем

## Краткая шпаргалка

| Вы видите | Сложность |
|-----------|-----------|
| Нет циклов, константные операции | O(1) |
| Цикл, делящий данные пополам | O(log n) |
| Один проход по данным | O(n) |
| Сортировка (эффективная) | O(n log n) |
| Два вложенных цикла | O(n²) |
| Три вложенных цикла | O(n³) |
| Рекурсия с двумя вызовами | O(2ⁿ) |
| Генерация всех перестановок | O(n!) |

---

**Предыдущая тема:** [Блок-схемы](./03-flowcharts.md)
