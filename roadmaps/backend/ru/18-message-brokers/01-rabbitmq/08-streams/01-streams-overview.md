# Обзор RabbitMQ Streams

[prev: 07-publisher-confirms](../07-tutorials/07-publisher-confirms.md) | [next: 02-stream-basics](./02-stream-basics.md)

---

## Введение

RabbitMQ Streams — это новый тип данных, представленный в RabbitMQ 3.9, который предоставляет функциональность append-only log (журнала с добавлением в конец). Streams разработаны для сценариев, где требуется высокая пропускная способность, повторное чтение сообщений и долгосрочное хранение данных.

## Что такое Streams?

Streams — это персистентная структура данных, которая:

- **Append-only**: сообщения добавляются только в конец потока
- **Immutable**: сообщения не могут быть изменены или удалены индивидуально
- **Replayable**: сообщения можно перечитывать многократно
- **Time-based retention**: хранение основано на времени или размере

```
┌─────────────────────────────────────────────────────────┐
│                    RabbitMQ Stream                       │
│                                                          │
│  ┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐     │
│  │ M1  │ M2  │ M3  │ M4  │ M5  │ M6  │ M7  │ ... │ →   │
│  └─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘     │
│    ↑                   ↑                   ↑            │
│  offset=0          offset=3            offset=6         │
│                                                          │
│  Consumer A ────────────────→                            │
│  Consumer B ──────→                                      │
│  Consumer C ──────────────────────────→                  │
└─────────────────────────────────────────────────────────┘
```

## Зачем нужны Streams?

### Основные сценарии использования

1. **Повторное чтение сообщений**
   - Классические очереди удаляют сообщение после подтверждения
   - Streams позволяют многократно перечитывать одни и те же данные

2. **Множественные потребители**
   - Каждый потребитель читает независимо со своего offset
   - Не нужно создавать отдельные очереди для каждого потребителя

3. **Высокая пропускная способность**
   - Оптимизированы для сценариев с большим объёмом сообщений
   - Эффективное использование дискового I/O

4. **Долгосрочное хранение**
   - Сообщения хранятся до истечения retention policy
   - Подходят для event sourcing и аудита

### Примеры использования

```python
# Сценарий: система аналитики событий
# Несколько сервисов читают один поток событий

# Сервис 1: Расчёт метрик в реальном времени
# → Читает с конца потока (latest)

# Сервис 2: Построение исторических отчётов
# → Перечитывает данные с начала (first)

# Сервис 3: Machine Learning pipeline
# → Читает данные за последние 24 часа (timestamp)
```

## Архитектура Streams

### Структура хранения

Streams используют segment-based storage:

```
Stream "events"
├── segment-0000000000.idx    # Индексный файл
├── segment-0000000000.log    # Данные сообщений
├── segment-0000001000.idx
├── segment-0000001000.log
└── ...
```

### Компоненты архитектуры

```
┌─────────────────────────────────────────────────────────────┐
│                     RabbitMQ Node                            │
│                                                              │
│  ┌─────────────────┐    ┌─────────────────┐                 │
│  │  AMQP Protocol  │    │ Stream Protocol │                 │
│  │    (5672)       │    │    (5552)       │                 │
│  └────────┬────────┘    └────────┬────────┘                 │
│           │                      │                           │
│           ▼                      ▼                           │
│  ┌──────────────────────────────────────────┐               │
│  │            Stream Engine                  │               │
│  │  ┌────────────┐  ┌────────────┐          │               │
│  │  │  Writers   │  │  Readers   │          │               │
│  │  └────────────┘  └────────────┘          │               │
│  └──────────────────────────────────────────┘               │
│                         │                                    │
│                         ▼                                    │
│  ┌──────────────────────────────────────────┐               │
│  │              Segment Files                │               │
│  │     (Persistent storage on disk)          │               │
│  └──────────────────────────────────────────┘               │
└─────────────────────────────────────────────────────────────┘
```

### Stream Protocol

RabbitMQ Streams используют специальный бинарный протокол:

- **Порт**: 5552 (по умолчанию)
- **Оптимизация**: минимальные накладные расходы
- **Batching**: группировка сообщений для эффективности

```python
# Подключение через Stream Protocol
# Требуется специальный клиент

# Python: rstream
# Java: rabbitmq-stream-java-client
# Go: rabbitmq-stream-go-client
# .NET: rabbitmq-stream-dotnet-client
```

## Репликация и надёжность

### Leader-Follower репликация

```
┌─────────────────────────────────────────────────────────┐
│                  Stream Replication                      │
│                                                          │
│  Node 1 (Leader)     Node 2 (Follower)   Node 3 (Follower)
│  ┌────────────┐      ┌────────────┐      ┌────────────┐ │
│  │  Stream    │ ───→ │  Replica   │      │  Replica   │ │
│  │  (write)   │      │  (read)    │      │  (read)    │ │
│  └────────────┘      └────────────┘      └────────────┘ │
│        │                    │                  │         │
│        ▼                    ▼                  ▼         │
│  ┌──────────────────────────────────────────────────┐   │
│  │              Raft Consensus                       │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

### Настройка репликации

```python
# Создание stream с репликацией через AMQP
import pika

connection = pika.BlockingConnection(
    pika.ConnectionParameters('localhost')
)
channel = connection.channel()

# Создание stream с 3 репликами
channel.queue_declare(
    queue='my-stream',
    arguments={
        'x-queue-type': 'stream',
        'x-initial-cluster-size': 3,  # Количество реплик
        'x-max-length-bytes': 1073741824,  # 1GB
        'x-max-age': '7D'  # Хранить 7 дней
    }
)
```

## Retention Policies

Streams поддерживают два типа retention:

### Time-based retention

```python
arguments = {
    'x-queue-type': 'stream',
    'x-max-age': '7D'  # Хранить 7 дней
    # Варианты: Y (годы), M (месяцы), D (дни), h (часы), m (минуты), s (секунды)
}
```

### Size-based retention

```python
arguments = {
    'x-queue-type': 'stream',
    'x-max-length-bytes': 10737418240  # 10GB максимум
}
```

### Комбинированный retention

```python
arguments = {
    'x-queue-type': 'stream',
    'x-max-age': '30D',  # Хранить 30 дней
    'x-max-length-bytes': 53687091200  # Но не более 50GB
}
# Применяется первое достигнутое ограничение
```

## Требования к системе

### Минимальные требования

- **RabbitMQ версия**: 3.9+
- **Erlang/OTP**: 23+
- **Плагин**: rabbitmq_stream (включён по умолчанию с 3.9)

### Проверка и активация

```bash
# Проверка статуса плагина
rabbitmq-plugins list | grep stream

# Активация плагина (если не активен)
rabbitmq-plugins enable rabbitmq_stream

# Проверка порта Stream Protocol
netstat -tlnp | grep 5552
```

## Ограничения Streams

1. **Нет удаления отдельных сообщений**
   - Удаление только через retention policy

2. **Нет приоритетов сообщений**
   - Все сообщения равнозначны

3. **Нет TTL для отдельных сообщений**
   - Только общий retention для всего stream

4. **Нет dead letter exchanges**
   - Сообщения не переносятся в DLX

5. **Ограниченная поддержка AMQP**
   - Для полной функциональности нужен Stream Protocol

## Best Practices

### Когда использовать Streams

- Event sourcing системы
- Логирование и аудит
- Аналитика в реальном времени
- Репликация данных между сервисами
- Системы с множественными потребителями

### Когда НЕ использовать Streams

- Простые task queues
- Сценарии с удалением/изменением сообщений
- Когда нужны dead letter exchanges
- Низкий объём сообщений

## Заключение

RabbitMQ Streams представляют собой мощный инструмент для сценариев, требующих:
- Высокой пропускной способности
- Повторного чтения сообщений
- Множественных независимых потребителей
- Долгосрочного хранения событий

Они дополняют классические очереди RabbitMQ, предоставляя функциональность, аналогичную Apache Kafka, но в рамках экосистемы RabbitMQ.

---

[prev: 07-publisher-confirms](../07-tutorials/07-publisher-confirms.md) | [next: 02-stream-basics](./02-stream-basics.md)
