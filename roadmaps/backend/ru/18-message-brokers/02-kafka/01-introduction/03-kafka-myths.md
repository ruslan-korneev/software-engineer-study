# Мифы о Kafka

[prev: 02-using-kafka](./02-using-kafka.md) | [next: 04-kafka-real-world](./04-kafka-real-world.md)

---

## Описание

Вокруг Apache Kafka сложилось множество заблуждений и мифов. Одни переоценивают её возможности, другие недооценивают сложность эксплуатации. Понимание реальных ограничений и возможностей Kafka поможет принять правильное решение при выборе технологии и избежать типичных ошибок.

## Ключевые концепции

### Структура разбора мифов

Для каждого мифа мы рассмотрим:
- **Миф** — распространённое заблуждение
- **Реальность** — как обстоят дела на самом деле
- **Важно знать** — практические рекомендации

## Примеры

### Миф 1: "Kafka гарантирует exactly-once доставку из коробки"

**Миф:**
Kafka автоматически обеспечивает exactly-once семантику — каждое сообщение обрабатывается ровно один раз.

**Реальность:**
По умолчанию Kafka обеспечивает **at-least-once** доставку. Это значит:
- Сообщение будет доставлено минимум один раз
- При сбоях возможны дубликаты
- Exactly-once требует дополнительной настройки

```
Семантики доставки:
┌─────────────────────────────────────────────────────────────┐
│  at-most-once   │  Сообщение может потеряться, но не       │
│                 │  дублируется. Producer fire-and-forget.   │
├─────────────────┼───────────────────────────────────────────┤
│  at-least-once  │  Сообщение доставляется минимум раз.     │
│   (по умолч.)   │  Возможны дубликаты при retry.           │
├─────────────────┼───────────────────────────────────────────┤
│  exactly-once   │  Сообщение доставляется ровно один раз.  │
│                 │  Требует идемпотентного producer +       │
│                 │  транзакций + правильной обработки.      │
└─────────────────┴───────────────────────────────────────────┘
```

**Как включить exactly-once:**

```python
from kafka import KafkaProducer

# Идемпотентный producer (Kafka 0.11+)
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    enable_idempotence=True,  # Ключевая настройка
    acks='all',               # Обязательно для идемпотентности
    retries=5,
    max_in_flight_requests_per_connection=5
)
```

```java
// Транзакционный producer
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("transactional.id", "my-transactional-id");
props.put("enable.idempotence", "true");

Producer<String, String> producer = new KafkaProducer<>(props);
producer.initTransactions();

try {
    producer.beginTransaction();
    producer.send(new ProducerRecord<>("topic1", "key", "value1"));
    producer.send(new ProducerRecord<>("topic2", "key", "value2"));
    producer.commitTransaction();
} catch (Exception e) {
    producer.abortTransaction();
}
```

**Важно знать:**
- Exactly-once работает только внутри Kafka (producer → broker → consumer)
- При записи во внешние системы (БД, API) нужна собственная идемпотентность
- Транзакции увеличивают latency и снижают throughput

---

### Миф 2: "Kafka — это просто очередь сообщений"

**Миф:**
Kafka — это улучшенная версия RabbitMQ или ActiveMQ.

**Реальность:**
Kafka — это **распределённая платформа потоковой передачи данных**, которая принципиально отличается от традиционных очередей:

| Характеристика | Традиционная очередь | Kafka |
|----------------|---------------------|-------|
| Модель | Point-to-point | Publish-subscribe + хранение |
| После чтения | Сообщение удаляется | Сообщение остаётся |
| Повторное чтение | Невозможно | Возможно (replay) |
| Масштабирование | Вертикальное | Горизонтальное |
| Порядок | Глобальный | В рамках партиции |
| Хранение | Временное | Долгосрочное (дни/недели) |

```
Традиционная очередь:
Producer → [Queue] → Consumer
                ↓
           Сообщение удаляется

Kafka:
Producer → [Topic/Partition] → Consumer A (offset: 5)
                             → Consumer B (offset: 3)
                             → Consumer C (offset: 8)
                ↓
           Сообщение хранится (retention)
```

**Важно знать:**
- Kafka лучше рассматривать как "распределённый лог"
- Возможность replay — одно из главных преимуществ
- Для паттерна request-response Kafka не оптимальна

---

### Миф 3: "Kafka гарантирует порядок сообщений"

**Миф:**
Все сообщения в топике обрабатываются строго в порядке отправки.

**Реальность:**
Kafka гарантирует порядок **только в рамках одной партиции**:

```
Topic с 3 партициями:

Producer отправляет: A, B, C, D, E, F

Партиция 0: [A][D]     → Consumer видит: A, D
Партиция 1: [B][E]     → Consumer видит: B, E
Партиция 2: [C][F]     → Consumer видит: C, F

Глобальный порядок НЕ гарантируется!
```

**Как обеспечить порядок:**

```python
# Используйте ключ партиционирования
# Все сообщения с одинаковым ключом попадут в одну партицию

# Все события пользователя — в одну партицию
producer.send('user-events', key=user_id.encode(), value=event)

# Все события заказа — в одну партицию
producer.send('order-events', key=order_id.encode(), value=event)
```

**Важно знать:**
- Если нужен глобальный порядок — используйте 1 партицию (но теряете параллелизм)
- Правильный выбор ключа партиционирования критически важен
- При изменении количества партиций маппинг ключ→партиция меняется

---

### Миф 4: "Kafka невозможно потерять данные"

**Миф:**
Если данные записаны в Kafka, они никогда не потеряются.

**Реальность:**
Потеря данных возможна в нескольких сценариях:

**Сценарий 1: Неправильные настройки producer**
```python
# ОПАСНО: fire-and-forget, данные могут потеряться
producer = KafkaProducer(bootstrap_servers=['localhost:9092'])
producer.send('topic', value=b'data')  # Не ждём подтверждения

# БЕЗОПАСНО: ждём подтверждения от всех реплик
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    acks='all',  # Ждём подтверждения от всех in-sync реплик
    retries=3
)
future = producer.send('topic', value=b'data')
future.get(timeout=10)  # Блокируемся до подтверждения
```

**Сценарий 2: Unclean leader election**
```
# Опасная ситуация:
1. Leader имеет сообщения 1-100
2. Follower синхронизировал только 1-90
3. Leader падает
4. Follower становится новым Leader
5. Сообщения 91-100 потеряны!

# Защита:
unclean.leader.election.enable=false (по умолчанию с Kafka 2.0)
```

**Сценарий 3: Retention policy**
```properties
# Данные удаляются по истечении времени
log.retention.hours=168  # 7 дней

# Или по размеру
log.retention.bytes=1073741824  # 1GB

# Если consumer отстал больше чем retention — данные потеряны!
```

**Важно знать:**
- `acks=all` + `min.insync.replicas=2` — базовая защита
- Мониторьте consumer lag
- Настройте retention с запасом

---

### Миф 5: "Kafka масштабируется бесконечно"

**Миф:**
Можно просто добавлять брокеры и партиции для любой нагрузки.

**Реальность:**
Есть практические ограничения:

```
Узкие места при масштабировании:
┌────────────────────────────────────────────────────────────┐
│  1. Количество партиций                                    │
│     - Больше партиций = больше файловых дескрипторов      │
│     - Больше партиций = дольше leader election            │
│     - Рекомендация: до 4000 партиций на брокер            │
├────────────────────────────────────────────────────────────┤
│  2. ZooKeeper (до KRaft)                                   │
│     - Ограничение ~200K партиций на кластер               │
│     - ZooKeeper становится узким местом                   │
├────────────────────────────────────────────────────────────┤
│  3. Rebalancing                                            │
│     - При добавлении consumer — перебалансировка          │
│     - Во время rebalance — обработка останавливается      │
├────────────────────────────────────────────────────────────┤
│  4. Consumer group                                         │
│     - Максимум consumer = количество партиций             │
│     - Больше consumer — они просто idle                   │
└────────────────────────────────────────────────────────────┘
```

**Важно знать:**
- Планируйте количество партиций заранее (увеличить легко, уменьшить нельзя)
- KRaft (без ZooKeeper) снимает многие ограничения
- Используйте Incremental Cooperative Rebalancing для минимизации простоев

---

### Миф 6: "Kafka заменяет базу данных"

**Миф:**
Можно хранить все данные в Kafka и использовать её как основное хранилище.

**Реальность:**
Kafka НЕ заменяет базу данных:

| Операция | База данных | Kafka |
|----------|-------------|-------|
| Чтение по ключу | O(1) или O(log n) | Невозможно напрямую |
| Сложные запросы | SQL, индексы | Нет |
| Обновление записи | UPDATE | Только append (новое сообщение) |
| Удаление записи | DELETE | Tombstone (сложно) |
| Транзакции ACID | Полные | Ограниченные |

**Правильные паттерны:**

```
1. Kafka + Materialized View (CQRS):

   Kafka (события) → Consumer → База данных (для запросов)

2. Event Sourcing + Snapshots:

   Kafka (все события) + Redis/DB (текущее состояние)

3. Kafka как CDC источник:

   MySQL → Debezium → Kafka → Elasticsearch/Analytics
```

**Важно знать:**
- Kafka — для событий и потоков, не для CRUD
- Используйте специализированные хранилища для запросов
- Log compaction позволяет хранить "последнее значение по ключу", но это не БД

---

### Миф 7: "Kafka сложно в эксплуатации"

**Миф:**
Kafka требует огромную команду для поддержки.

**Реальность:**
Это было правдой раньше, но ситуация улучшилась:

**Что упростилось:**
- **KRaft** (Kafka 3.0+) — больше не нужен ZooKeeper
- **Managed Kafka** — Confluent Cloud, AWS MSK, Aiven
- **Kubernetes operators** — Strimzi для автоматизации
- **Лучший инструментарий** — UI, мониторинг, CLI

**Что по-прежнему сложно:**
```
Задачи эксплуатации:
┌────────────────────────────────────────────────────────────┐
│  ✓ Деплой             │  Упростился с Docker/K8s          │
│  ✓ Базовая настройка  │  Разумные дефолты                 │
├────────────────────────────────────────────────────────────┤
│  ⚠ Масштабирование    │  Требует планирования             │
│  ⚠ Тюнинг под нагрузку│  Много параметров                 │
│  ⚠ Обновления версий  │  Rolling upgrades                 │
├────────────────────────────────────────────────────────────┤
│  ✗ Отладка проблем    │  Требует глубокого понимания      │
│  ✗ Disaster recovery  │  Сложные сценарии                 │
└────────────────────────────────────────────────────────────┘
```

**Важно знать:**
- Для начала используйте managed сервисы
- Инвестируйте в мониторинг (Prometheus + Grafana)
- Автоматизируйте типовые операции

---

### Миф 8: "Consumer всегда получит сообщение"

**Миф:**
Если producer записал сообщение, consumer его обязательно получит.

**Реальность:**
Есть несколько случаев, когда consumer пропустит сообщения:

```python
# Случай 1: auto.offset.reset = 'latest' (по умолчанию)
# Новый consumer начинает читать с конца — старые сообщения пропущены

consumer = KafkaConsumer(
    'topic',
    group_id='new-group',
    auto_offset_reset='latest'  # Пропустит все старые сообщения!
)

# Случай 2: Consumer отстал больше чем retention
# Сообщения удалены до того, как consumer их прочитал

# Случай 3: enable.auto.commit=True + crash до обработки
# Offset закоммичен, но сообщение не обработано

consumer = KafkaConsumer(
    'topic',
    enable_auto_commit=True,  # Опасно!
    auto_commit_interval_ms=1000
)
for msg in consumer:
    process(msg)  # Если упадёт здесь — сообщение потеряно
```

**Безопасный паттерн:**

```python
consumer = KafkaConsumer(
    'topic',
    group_id='my-group',
    enable_auto_commit=False,  # Ручной commit
    auto_offset_reset='earliest'  # Читать с начала для новых групп
)

for msg in consumer:
    try:
        process(msg)
        consumer.commit()  # Commit после успешной обработки
    except Exception as e:
        # Не коммитим — сообщение будет перечитано
        handle_error(e)
```

---

### Миф 9: "Больше партиций = лучше производительность"

**Миф:**
Чем больше партиций, тем быстрее система.

**Реальность:**
Зависимость нелинейная, есть точка убывающей отдачи:

```
Производительность vs Партиции:

Throughput
    │
    │         ┌─── Оптимум
    │        /│\
    │       / │ \___________
    │      /  │
    │     /   │
    │    /    │
    │___/     │
    └─────────┴───────────── Партиции
              ↑
         После этой точки
         overhead растёт
```

**Негативные эффекты большого числа партиций:**
- Больше файловых дескрипторов на брокере
- Дольше leader election при падении брокера
- Больше latency при producer acks=all
- Больше overhead на метаданные

**Практические рекомендации:**

```
Формула для начала:
Партиции = max(Throughput / Producer_Throughput,
               Throughput / Consumer_Throughput)

Где:
- Throughput — целевая пропускная способность
- Producer_Throughput — ~10 MB/s на партицию
- Consumer_Throughput — ~25-30 MB/s на партицию

Пример:
- Нужно 100 MB/s
- Партиции = max(100/10, 100/25) = max(10, 4) = 10 партиций
```

---

### Миф 10: "ZooKeeper больше не нужен"

**Миф:**
С выходом KRaft можно забыть про ZooKeeper.

**Реальность:**
Переход постепенный:

```
Timeline KRaft:
┌──────────────────────────────────────────────────────────────┐
│ Kafka 2.8   │ KRaft preview (не для production)              │
│ Kafka 3.0   │ KRaft production-ready (ограниченно)          │
│ Kafka 3.3   │ KRaft полностью поддерживается                │
│ Kafka 3.5   │ ZooKeeper deprecated                          │
│ Kafka 4.0   │ ZooKeeper будет удалён                        │
└──────────────────────────────────────────────────────────────┘
```

**Что нужно знать:**
- Для новых проектов — используйте KRaft
- Для существующих — планируйте миграцию
- Миграция ZooKeeper → KRaft возможна без downtime

## Best Practices

### Чек-лист развенчания мифов при проектировании

```
□ Проверили семантику доставки (at-least-once по умолчанию)
□ Спланировали ключи партиционирования для порядка
□ Настроили acks=all и min.insync.replicas
□ Рассчитали retention с запасом
□ Не используем Kafka как базу данных
□ Количество партиций обосновано расчётами
□ Есть план мониторинга consumer lag
□ Настроен ручной commit offset
□ Есть стратегия обработки ошибок (DLQ)
□ Понимаем ограничения масштабирования
```

### Частые ошибки и решения

| Ошибка | Решение |
|--------|---------|
| Ожидание exactly-once без настройки | Включите idempotence и транзакции |
| Надежда на глобальный порядок | Используйте ключ партиционирования |
| acks=1 в production | Всегда acks=all |
| auto.commit=true | Ручной commit после обработки |
| Слишком много/мало партиций | Расчёт по формуле throughput |
| Kafka как единственное хранилище | Добавьте materialized view |

## Краткое резюме

Большинство мифов о Kafka возникают из-за непонимания её архитектуры или экстраполяции поведения традиционных систем. Kafka — мощный инструмент, но требует осознанного подхода: правильной настройки семантики доставки, понимания гарантий порядка, грамотного планирования партиций и retention. Не бойтесь Kafka, но и не недооценивайте её особенности — это ключ к успешному использованию.

---

[prev: 02-using-kafka](./02-using-kafka.md) | [next: 04-kafka-real-world](./04-kafka-real-world.md)
