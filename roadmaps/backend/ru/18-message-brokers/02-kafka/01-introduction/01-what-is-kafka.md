# Что такое Kafka?

## Описание

Apache Kafka — это распределённая платформа потоковой передачи данных (distributed streaming platform), разработанная для обработки больших объёмов данных в реальном времени. Kafka была создана в LinkedIn в 2010 году для решения проблемы обработки миллионов событий в секунду. В 2011 году проект был передан в Apache Software Foundation и стал проектом с открытым исходным кодом.

Kafka часто описывают как "распределённый журнал коммитов" (distributed commit log), потому что в её основе лежит простая, но мощная концепция: все сообщения записываются в упорядоченный, неизменяемый журнал, который можно читать многократно.

### Почему "Kafka"?

Создатель Kafka, Джей Крепс (Jay Kreps), назвал систему в честь писателя Франца Кафки. По его словам, название было выбрано потому что "это система, оптимизированная для записи", а Кафка был писателем.

## Ключевые концепции

### Основные компоненты

**1. Сообщение (Message/Record)**
- Базовая единица данных в Kafka
- Состоит из ключа (опционально), значения и метаданных
- Сообщения неизменяемы после записи

```
┌─────────────────────────────────────┐
│           Message/Record            │
├─────────────────────────────────────┤
│  Key (optional)    │  "user_123"    │
│  Value             │  {"event":...} │
│  Timestamp         │  1703686800000 │
│  Headers           │  {"type":"v1"} │
└─────────────────────────────────────┘
```

**2. Топик (Topic)**
- Категория или канал, куда публикуются сообщения
- Аналогия: папка в файловой системе или таблица в базе данных
- Топики разделены на партиции для параллельной обработки

**3. Партиция (Partition)**
- Упорядоченная, неизменяемая последовательность сообщений
- Каждое сообщение получает уникальный offset (смещение)
- Партиции распределяются по брокерам

```
Topic: orders
┌────────────────────────────────────────────────┐
│  Partition 0: [0][1][2][3][4][5]              │
│  Partition 1: [0][1][2][3]                    │
│  Partition 2: [0][1][2][3][4][5][6][7]        │
└────────────────────────────────────────────────┘
```

**4. Брокер (Broker)**
- Сервер Kafka, хранящий данные
- Кластер состоит из нескольких брокеров
- Каждый брокер идентифицируется уникальным ID

**5. Producer (Производитель)**
- Приложение, которое отправляет сообщения в топики
- Отвечает за выбор партиции для записи

**6. Consumer (Потребитель)**
- Приложение, которое читает сообщения из топиков
- Может читать с любого offset

**7. Consumer Group**
- Группа потребителей, совместно читающих топик
- Каждая партиция назначается только одному потребителю в группе
- Обеспечивает параллельную обработку и отказоустойчивость

### Ключевые характеристики

| Характеристика | Описание |
|----------------|----------|
| **Высокая пропускная способность** | Миллионы сообщений в секунду |
| **Низкая задержка** | Миллисекунды от записи до чтения |
| **Масштабируемость** | Горизонтальное масштабирование добавлением брокеров |
| **Надёжность** | Репликация данных между брокерами |
| **Долговечность** | Данные хранятся на диске |
| **Отказоустойчивость** | Автоматическое восстановление при сбоях |

## Примеры

### Архитектура кластера Kafka

```
                    ┌─────────────────────────────────────┐
                    │          Kafka Cluster              │
                    │                                     │
┌──────────┐        │  ┌─────────┐  ┌─────────┐          │        ┌──────────┐
│ Producer │───────▶│  │ Broker 1│  │ Broker 2│          │───────▶│ Consumer │
└──────────┘        │  │  P0,P1  │  │  P2,P3  │          │        └──────────┘
                    │  └─────────┘  └─────────┘          │
┌──────────┐        │       │           │                │        ┌──────────┐
│ Producer │───────▶│       │           │                │───────▶│ Consumer │
└──────────┘        │       └─────┬─────┘                │        └──────────┘
                    │             │                      │
                    │       ┌─────────┐                  │
                    │       │ZooKeeper│                  │
                    │       │ / KRaft │                  │
                    │       └─────────┘                  │
                    └─────────────────────────────────────┘
```

### Пример записи сообщения (Java)

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // Настройка producer
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer",
            "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer",
            "org.apache.kafka.common.serialization.StringSerializer");

        // Создание producer
        Producer<String, String> producer = new KafkaProducer<>(props);

        // Отправка сообщения
        ProducerRecord<String, String> record =
            new ProducerRecord<>("orders", "order_1", "{\"product\": \"laptop\"}");

        producer.send(record, (metadata, exception) -> {
            if (exception == null) {
                System.out.println("Сообщение отправлено в партицию " +
                    metadata.partition() + " с offset " + metadata.offset());
            }
        });

        producer.close();
    }
}
```

### Пример чтения сообщений (Python)

```python
from kafka import KafkaConsumer
import json

# Создание consumer
consumer = KafkaConsumer(
    'orders',
    bootstrap_servers=['localhost:9092'],
    group_id='order-processor',
    auto_offset_reset='earliest',
    value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

# Чтение сообщений
for message in consumer:
    print(f"Партиция: {message.partition}")
    print(f"Offset: {message.offset}")
    print(f"Ключ: {message.key}")
    print(f"Значение: {message.value}")
    print("---")
```

## Best Practices

### При выборе Kafka

**Используйте Kafka когда:**
- Нужна высокая пропускная способность (>100K сообщений/сек)
- Требуется надёжное хранение сообщений
- Несколько потребителей читают одни и те же данные
- Нужна потоковая обработка данных
- Требуется replay сообщений

**Не используйте Kafka когда:**
- Простые задачи с малым объёмом сообщений
- Нужны сложные паттерны маршрутизации (рассмотрите RabbitMQ)
- Критична минимальная задержка < 1мс
- Нет ресурсов на администрирование кластера

### Проектирование топиков

1. **Именование топиков** — используйте понятные имена: `orders.created`, `payments.processed`
2. **Количество партиций** — планируйте с запасом, увеличить легко, уменьшить нельзя
3. **Фактор репликации** — минимум 3 для production-систем
4. **Retention** — настройте политику хранения в соответствии с требованиями

### Производительность

- Используйте batch-отправку сообщений
- Настройте compression (lz4 или snappy)
- Правильно выбирайте ключ партиционирования
- Мониторьте consumer lag

## Краткое резюме

Apache Kafka — это не просто очередь сообщений, а полноценная платформа для потоковой обработки данных. Её ключевые преимущества: высокая производительность, надёжность, масштабируемость и способность хранить данные долгое время. Kafka стала стандартом де-факто для построения event-driven архитектур и систем реального времени в крупных компаниях по всему миру.
