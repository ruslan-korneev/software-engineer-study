# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (Caching)

[prev: 18-sharding-and-replication](./18-sharding-and-replication.md) | [next: 20-asynchronism](./20-asynchronism.md)

---

## –í–≤–µ–¥–µ–Ω–∏–µ

**–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî —ç—Ç–æ —Ç–µ—Ö–Ω–∏–∫–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–ø–∏–π –¥–∞–Ω–Ω—ã—Ö –≤ –±—ã—Å—Ç—Ä–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (–∫—ç—à–µ) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–∏–º –¥–∞–Ω–Ω—ã–º. –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π —Ä–∞–∑ –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é (–∑–∞–ø—Ä–æ—Å –∫ –ë–î, –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ, —Å–µ—Ç–µ–≤–æ–π –∑–∞–ø—Ä–æ—Å), —Å–∏—Å—Ç–µ–º–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞—Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

### –ó–∞—á–µ–º –Ω—É–∂–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ?

1. **–°–Ω–∏–∂–µ–Ω–∏–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏** ‚Äî –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –∑–∞ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã –≤–º–µ—Å—Ç–æ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥
2. **–£–º–µ–Ω—å—à–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ backend** ‚Äî –º–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∏ API
3. **–≠–∫–æ–Ω–æ–º–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤** ‚Äî –º–µ–Ω—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –º–µ–Ω—å—à–µ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞
4. **–ü–æ–≤—ã—à–µ–Ω–∏–µ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏** ‚Äî –∫—ç—à –º–æ–∂–µ—Ç –æ—Ç–¥–∞–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, –¥–∞–∂–µ –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
5. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** ‚Äî —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ –ë–î

### –ü—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    –∑–∞–ø—Ä–æ—Å     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    cache miss    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Client ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Cache  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Database ‚îÇ
‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    –æ—Ç–≤–µ—Ç      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    –¥–∞–Ω–Ω—ã–µ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                          cache hit
                               ‚îÇ
                               ‚ñº
                         –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç
```

**Cache hit** ‚Äî –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫—ç—à–µ (–±—ã—Å—Ç—Ä–æ)
**Cache miss** ‚Äî –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–ø—Ä–æ—Å –∏–¥—ë—Ç –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É (–º–µ–¥–ª–µ–Ω–Ω–æ)

**Hit ratio** = cache hits / (cache hits + cache misses) ‚Äî –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫—ç—à–∞

---

## –£—Ä–æ–≤–Ω–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö —Å–∏—Å—Ç–µ–º—ã:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Browser  ‚îÇ   ‚îÇ CDN ‚îÇ   ‚îÇ App     ‚îÇ   ‚îÇ Database     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Cache    ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ Cache   ‚îÇ   ‚îÇ Cache        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ       ‚ñ≤            ‚ñ≤           ‚ñ≤              ‚ñ≤            ‚îÇ
‚îÇ       ‚îÇ            ‚îÇ           ‚îÇ              ‚îÇ            ‚îÇ
‚îÇ    Client        Edge       Server        Storage          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. Client-side Cache (–ë—Ä–∞—É–∑–µ—Ä–Ω—ã–π –∫—ç—à)

–ë—Ä–∞—É–∑–µ—Ä –∫—ç—à–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ—Å—É—Ä—Å—ã –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

**HTTP-–∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫—ç—à–µ–º:**

```http
# Cache-Control ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
Cache-Control: max-age=31536000, public, immutable

# –í–∞—Ä–∏–∞–Ω—Ç—ã:
Cache-Control: no-cache        # –ü—Ä–æ–≤–µ—Ä—è—Ç—å —Å–≤–µ–∂–µ—Å—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
Cache-Control: no-store        # –ù–µ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –≤–æ–æ–±—â–µ
Cache-Control: private         # –¢–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
Cache-Control: public          # –ú–æ–∂–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ CDN
Cache-Control: max-age=3600    # –•—Ä–∞–Ω–∏—Ç—å 1 —á–∞—Å

# ETag ‚Äî —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π
ETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"

# Last-Modified ‚Äî –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
Last-Modified: Wed, 21 Oct 2023 07:28:00 GMT

# Expires (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π, –Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
Expires: Thu, 01 Dec 2024 16:00:00 GMT
```

**–£—Å–ª–æ–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:**

```http
# –ö–ª–∏–µ–Ω—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∫—ç—à–∞
If-None-Match: "33a64df551425fcc55e4d42a148795d9f25f89d4"
If-Modified-Since: Wed, 21 Oct 2023 07:28:00 GMT

# –°–µ—Ä–≤–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç:
# 304 Not Modified ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∫—ç—à
# 200 OK + –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî –æ–±–Ω–æ–≤–∏ –∫—ç—à
```

**–ü—Ä–∏–º–µ—Ä –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ nginx:**

```nginx
location /static/ {
    # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å –≤–µ—Ä—Å–∏–µ–π –≤ –∏–º–µ–Ω–∏
    expires 1y;
    add_header Cache-Control "public, immutable";
}

location /api/ {
    # API –Ω–µ –∫—ç—à–∏—Ä—É–µ–º
    add_header Cache-Control "no-store";
}

location / {
    # HTML ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–µ–∂–µ—Å—Ç—å
    add_header Cache-Control "no-cache";
    etag on;
}
```

### 2. CDN Cache

CDN (Content Delivery Network) –∫—ç—à–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ edge-—Å–µ—Ä–≤–µ—Ä–∞—Ö –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User    ‚îÇ                                    ‚îÇ  Origin  ‚îÇ
‚îÇ  Moscow  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Server  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ                          ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ    ‚îÇ                  ‚îÇ  ‚îÇ
‚îÇ  User    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§   CDN Edge       ‚îÇ‚îÄ‚îÄ‚îò
‚îÇ  Berlin  ‚îÇ    ‚îÇ    ‚îÇ   (Frankfurt)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îÇ                  ‚îÇ
                ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  User    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  Paris   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ß—Ç–æ –∫—ç—à–∏—Ä—É–µ—Ç CDN:**
- –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã (JS, CSS, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
- –í–∏–¥–µ–æ –∏ –º–µ–¥–∏–∞
- API-–æ—Ç–≤–µ—Ç—ã (—Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π)
- HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã

**–ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Cloudflare:**

```
# Page Rules
URL: example.com/api/*
Cache Level: Standard
Edge Cache TTL: 1 hour

URL: example.com/static/*
Cache Level: Cache Everything
Edge Cache TTL: 1 year
```

### 3. Application Cache

–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ‚Äî Redis, Memcached, in-memory.

```python
import redis
import json
from functools import wraps

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache(ttl=300):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á –∏–∑ –∏–º–µ–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            cache_key = f"{func.__name__}:{args}:{kwargs}"

            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = func(*args, **kwargs)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            redis_client.setex(
                cache_key,
                ttl,
                json.dumps(result)
            )

            return result
        return wrapper
    return decorator

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
@cache(ttl=600)
def get_user_profile(user_id: int) -> dict:
    """–¢—è–∂—ë–ª—ã–π –∑–∞–ø—Ä–æ—Å –∫ –ë–î"""
    return db.query(
        "SELECT * FROM users WHERE id = %s",
        [user_id]
    )

# –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ ‚Äî –∑–∞–ø—Ä–æ—Å –∫ –ë–î
profile = get_user_profile(123)  # ~50ms

# –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤ ‚Äî –∏–∑ –∫—ç—à–∞
profile = get_user_profile(123)  # ~1ms
```

**In-memory –∫—ç—à (–¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤):**

```python
from functools import lru_cache
from cachetools import TTLCache
import time

# –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π LRU –∫—ç—à Python
@lru_cache(maxsize=1000)
def fibonacci(n):
    if n < 2:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# –ö—ç—à —Å TTL
cache = TTLCache(maxsize=1000, ttl=300)

def get_user(user_id):
    if user_id in cache:
        return cache[user_id]

    user = db.get_user(user_id)
    cache[user_id] = user
    return user
```

### 4. Database Cache

**Query Cache (MySQL):**

```sql
-- –í–∫–ª—é—á–µ–Ω–∏–µ query cache (—É—Å—Ç–∞—Ä–µ–ª–æ –≤ MySQL 8.0+)
SET GLOBAL query_cache_type = ON;
SET GLOBAL query_cache_size = 268435456;  -- 256MB

-- –ó–∞–ø—Ä–æ—Å –±—É–¥–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å—Å—è
SELECT SQL_CACHE * FROM products WHERE category_id = 5;

-- –ó–∞–ø—Ä–æ—Å –Ω–µ –±—É–¥–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å—Å—è
SELECT SQL_NO_CACHE * FROM products WHERE category_id = 5;
```

**Buffer Pool (InnoDB):**

```sql
-- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—É—Ñ–µ—Ä–Ω–æ–≥–æ –ø—É–ª–∞
SET GLOBAL innodb_buffer_pool_size = 8589934592;  -- 8GB

-- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
SHOW STATUS LIKE 'Innodb_buffer_pool%';
```

**PostgreSQL Shared Buffers:**

```sql
-- postgresql.conf
shared_buffers = 4GB
effective_cache_size = 12GB

-- –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞
SELECT
    sum(heap_blks_read) as heap_read,
    sum(heap_blks_hit) as heap_hit,
    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) as ratio
FROM pg_statio_user_tables;
```

### 5. CPU Cache (L1, L2, L3)

–ê–ø–ø–∞—Ä–∞—Ç–Ω—ã–π –∫—ç—à –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ ‚Äî —Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π, –Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CPU                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Core 0           Core 1                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ L1d ‚îÇ 32KB    ‚îÇ L1d ‚îÇ  ‚Üê –î–∞–Ω–Ω—ã–µ      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ L1i ‚îÇ 32KB    ‚îÇ L1i ‚îÇ  ‚Üê –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     ‚îÇ               ‚îÇ                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ L2  ‚îÇ 256KB   ‚îÇ L2  ‚îÇ  ‚Üê Per-core    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          ‚îå‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ L3  ‚îÇ 8-30MB  ‚Üê Shared        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–°–∫–æ—Ä–æ—Å—Ç—å –¥–æ—Å—Ç—É–ø–∞:
L1:  ~1 ns    (4 —Ç–∞–∫—Ç–∞)
L2:  ~4 ns    (12 —Ç–∞–∫—Ç–æ–≤)
L3:  ~12 ns   (36 —Ç–∞–∫—Ç–æ–≤)
RAM: ~100 ns  (300+ —Ç–∞–∫—Ç–æ–≤)
```

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è CPU –∫—ç—à–∞:**

```python
# –ü–ª–æ—Ö–æ ‚Äî —Å–ª—É—á–∞–π–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–∞–º—è—Ç–∏ (cache misses)
matrix = [[0] * 1000 for _ in range(1000)]
for j in range(1000):
    for i in range(1000):
        matrix[i][j] = i + j  # –ü—Ä—ã–≥–∞–µ–º –ø–æ –ø–∞–º—è—Ç–∏

# –•–æ—Ä–æ—à–æ ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø (cache-friendly)
for i in range(1000):
    for j in range(1000):
        matrix[i][j] = i + j  # –ò–¥—ë–º –ø–æ —Å—Ç—Ä–æ–∫–µ
```

---

## –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

### 1. Cache-Aside (Lazy Loading)

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å–∞–º–æ —É–ø—Ä–∞–≤–ª—è–µ—Ç –∫—ç—à–µ–º ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–≥—Ä—É–∂–∞–µ—Ç, –æ–±–Ω–æ–≤–ª—è–µ—Ç.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  1. get   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Cache  ‚îÇ
‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ
‚îÇ         ‚îÇ  2. miss  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ         ‚îÇ
‚îÇ         ‚îÇ  3. query ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ   DB    ‚îÇ
‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ
‚îÇ         ‚îÇ  4. data  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ         ‚îÇ
‚îÇ         ‚îÇ  5. set   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Cache  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
class UserRepository:
    def __init__(self, db, cache):
        self.db = db
        self.cache = cache

    def get_user(self, user_id: int) -> dict:
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = f"user:{user_id}"
        cached = self.cache.get(cache_key)

        if cached:
            return cached  # Cache hit

        # 2. Cache miss ‚Äî –∏–¥—ë–º –≤ –ë–î
        user = self.db.query(
            "SELECT * FROM users WHERE id = %s",
            [user_id]
        )

        if user:
            # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.cache.set(cache_key, user, ttl=3600)

        return user

    def update_user(self, user_id: int, data: dict):
        # –û–±–Ω–æ–≤–ª—è–µ–º –ë–î
        self.db.update("users", user_id, data)

        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à
        self.cache.delete(f"user:{user_id}")
```

**–ü–ª—é—Å—ã:**
- –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
- –ö—ç—à–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- –û—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å ‚Äî –µ—Å–ª–∏ –∫—ç—à —É–ø–∞–ª, —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç

**–ú–∏–Ω—É—Å—ã:**
- Cache miss = –∑–∞–¥–µ—Ä–∂–∫–∞
- –í–æ–∑–º–æ–∂–Ω–∞ —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

### 2. Read-Through

–ö—ç—à —Å–∞–º –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ miss. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∫—ç—à–µ–º.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  1. get   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  2. load  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Cache  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ   DB    ‚îÇ
‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  3. data  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  data     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
class ReadThroughCache:
    def __init__(self, cache, loader):
        self.cache = cache
        self.loader = loader  # –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –ë–î

    def get(self, key: str):
        value = self.cache.get(key)

        if value is None:
            # –ö—ç—à —Å–∞–º –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ
            value = self.loader(key)
            if value:
                self.cache.set(key, value)

        return value

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
def load_user_from_db(key: str):
    user_id = key.split(":")[1]
    return db.query("SELECT * FROM users WHERE id = %s", [user_id])

cache = ReadThroughCache(redis_client, load_user_from_db)
user = cache.get("user:123")  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏ miss
```

**–ü–ª—é—Å—ã:**
- –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –∑–Ω–∞–µ—Ç –æ –ª–æ–≥–∏–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏
- –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π –∫–æ–¥

**–ú–∏–Ω—É—Å—ã:**
- –°–ª–æ–∂–Ω–µ–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å
- –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤—Å—ë –µ—â—ë –º–µ–¥–ª–µ–Ω–Ω—ã–π

### 3. Write-Through

–ü—Ä–∏ –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∏ –≤ –∫—ç—à, –∏ –≤ –ë–î.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  1. write ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  2. write ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Cache  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ   DB    ‚îÇ
‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  4. ack   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  3. ack   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
class WriteThroughCache:
    def __init__(self, cache, db):
        self.cache = cache
        self.db = db

    def write(self, key: str, value: dict):
        # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ –æ–±–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        self.db.save(key, value)
        self.cache.set(key, value)

    def get(self, key: str):
        # –î–∞–Ω–Ω—ã–µ –≤—Å–µ–≥–¥–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã –≤ –∫—ç—à–µ
        return self.cache.get(key)
```

**–ü–ª—é—Å—ã:**
- –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
- –ö—ç—à –≤—Å–µ–≥–¥–∞ –∞–∫—Ç—É–∞–ª–µ–Ω

**–ú–∏–Ω—É—Å—ã:**
- –í—ã—Å–æ–∫–∞—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏
- –ö—ç—à–∏—Ä—É—é—Ç—Å—è –¥–∞–∂–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ

### 4. Write-Behind (Write-Back)

–ó–∞–ø–∏—Å—å —Å–Ω–∞—á–∞–ª–∞ –∏–¥—ë—Ç –≤ –∫—ç—à, –∑–∞—Ç–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤ –ë–î.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  1. write ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Cache  ‚îÇ
‚îÇ         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  2. ack   ‚îÇ         ‚îÇ
                      ‚îÇ  async  ‚îÇ
                      ‚îÇ    ‚ñº    ‚îÇ
                      ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  3. batch write
                      ‚îÇ ‚îÇQueue‚îÇ ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ DB
                      ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
import asyncio
from collections import deque
import time

class WriteBehindCache:
    def __init__(self, cache, db, flush_interval=5, batch_size=100):
        self.cache = cache
        self.db = db
        self.write_queue = deque()
        self.flush_interval = flush_interval
        self.batch_size = batch_size

    async def write(self, key: str, value: dict):
        # –ë—ã—Å—Ç—Ä–∞—è –∑–∞–ø–∏—Å—å –≤ –∫—ç—à
        self.cache.set(key, value)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ –∑–∞–ø–∏—Å—å –≤ –ë–î
        self.write_queue.append((key, value, time.time()))

        # –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –±–æ–ª—å—à–∞—è ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
        if len(self.write_queue) >= self.batch_size:
            await self._flush()

    async def _flush(self):
        """–ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ –ë–î"""
        if not self.write_queue:
            return

        batch = []
        while self.write_queue and len(batch) < self.batch_size:
            batch.append(self.write_queue.popleft())

        # Batch insert –≤ –ë–î
        await self.db.batch_upsert(batch)

    async def background_flush(self):
        """–§–æ–Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Å–±—Ä–æ—Å–∞"""
        while True:
            await asyncio.sleep(self.flush_interval)
            await self._flush()
```

**–ü–ª—é—Å—ã:**
- –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è –∑–∞–ø–∏—Å—å
- Batch-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ë–î

**–ú–∏–Ω—É—Å—ã:**
- –†–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏ –∫—ç—à–∞
- –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
- Eventual consistency

### 5. Refresh-Ahead

–£–ø—Ä–µ–∂–¥–∞—é—â–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è TTL.

```
TTL = 60 —Å–µ–∫
Refresh threshold = 50 —Å–µ–∫ (83%)

0s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 50s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 60s
‚îÇ                                ‚îÇ                  ‚îÇ
‚ñº                                ‚ñº                  ‚ñº
[‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –î–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ][‚îÄ Refresh zone ‚îÄ][Expired]
                                 ‚îÇ
                            –§–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
```

```python
import asyncio
import time

class RefreshAheadCache:
    def __init__(self, cache, loader, ttl=60, refresh_threshold=0.8):
        self.cache = cache
        self.loader = loader
        self.ttl = ttl
        self.refresh_threshold = refresh_threshold  # 80% –æ—Ç TTL
        self.refreshing = set()  # –ö–ª—é—á–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è

    async def get(self, key: str):
        data, created_at = self.cache.get_with_metadata(key)

        if data is None:
            # Cache miss ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
            return await self._load_and_cache(key)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å –∑–∞—Ä–∞–Ω–µ–µ
        age = time.time() - created_at
        if age > self.ttl * self.refresh_threshold:
            if key not in self.refreshing:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
                asyncio.create_task(self._refresh(key))

        return data

    async def _refresh(self, key: str):
        """–§–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ"""
        self.refreshing.add(key)
        try:
            await self._load_and_cache(key)
        finally:
            self.refreshing.discard(key)

    async def _load_and_cache(self, key: str):
        data = await self.loader(key)
        self.cache.set_with_metadata(key, data, time.time(), self.ttl)
        return data
```

**–ü–ª—é—Å—ã:**
- –í—Å–µ–≥–¥–∞ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
- –ù–µ—Ç –∑–∞–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏

**–ú–∏–Ω—É—Å—ã:**
- –ò–∑–±—ã—Ç–æ—á–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
- –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

---

## –ü–æ–ª–∏—Ç–∏–∫–∏ –≤—ã—Ç–µ—Å–Ω–µ–Ω–∏—è (Eviction Policies)

–ö–æ–≥–¥–∞ –∫—ç—à –∑–∞–ø–æ–ª–Ω–µ–Ω, –Ω—É–∂–Ω–æ —Ä–µ—à–∏—Ç—å, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–∏—Ç—å.

### 1. LRU (Least Recently Used)

–£–¥–∞–ª—è–µ—Ç—Å—è —ç–ª–µ–º–µ–Ω—Ç, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –¥–æ–ª—å—à–µ –≤—Å–µ–≥–æ –Ω–µ –æ–±—Ä–∞—â–∞–ª–∏—Å—å.

```
–ö—ç—à (max=3): [A, B, C]

get(A) ‚Üí [B, C, A]    # A –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –≤ –∫–æ–Ω–µ—Ü
set(D) ‚Üí [C, A, D]    # B —É–¥–∞–ª—è–µ—Ç—Å—è (—Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π)
get(C) ‚Üí [A, D, C]    # C –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –≤ –∫–æ–Ω–µ—Ü
```

```python
from collections import OrderedDict

class LRUCache:
    def __init__(self, capacity: int):
        self.cache = OrderedDict()
        self.capacity = capacity

    def get(self, key: str):
        if key not in self.cache:
            return None

        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –∫–æ–Ω–µ—Ü (—Å–∞–º—ã–π —Å–≤–µ–∂–∏–π)
        self.cache.move_to_end(key)
        return self.cache[key]

    def set(self, key: str, value):
        if key in self.cache:
            self.cache.move_to_end(key)
        else:
            if len(self.cache) >= self.capacity:
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π (–ø–µ—Ä–≤—ã–π)
                self.cache.popitem(last=False)

        self.cache[key] = value
```

**Redis LRU:**

```bash
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis
maxmemory 4gb
maxmemory-policy allkeys-lru

# –í–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–ª–∏—Ç–∏–∫:
# volatile-lru    ‚Äî LRU —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–ª—é—á–µ–π —Å TTL
# allkeys-lru     ‚Äî LRU –¥–ª—è –≤—Å–µ—Ö –∫–ª—é—á–µ–π
# volatile-random ‚Äî —Å–ª—É—á–∞–π–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–π —Å TTL
# allkeys-random  ‚Äî —Å–ª—É—á–∞–π–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–ª—é—á–µ–π
# volatile-ttl    ‚Äî —É–¥–∞–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–π —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º TTL
# noeviction      ‚Äî –æ—Ç–∫–∞–∑ –≤ –∑–∞–ø–∏—Å–∏ –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏
```

### 2. LFU (Least Frequently Used)

–£–¥–∞–ª—è–µ—Ç—Å—è —ç–ª–µ–º–µ–Ω—Ç —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–π.

```python
from collections import defaultdict
import heapq

class LFUCache:
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}           # key -> value
        self.freq = {}            # key -> frequency
        self.freq_to_keys = defaultdict(list)  # freq -> [keys]
        self.min_freq = 0
        self.time = 0             # –î–ª—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∏—á—å–∏—Ö

    def get(self, key: str):
        if key not in self.cache:
            return None

        self._update_freq(key)
        return self.cache[key]

    def set(self, key: str, value):
        if self.capacity == 0:
            return

        if key in self.cache:
            self.cache[key] = value
            self._update_freq(key)
            return

        if len(self.cache) >= self.capacity:
            self._evict()

        self.cache[key] = value
        self.freq[key] = 1
        self.freq_to_keys[1].append((self.time, key))
        self.min_freq = 1
        self.time += 1

    def _update_freq(self, key: str):
        f = self.freq[key]
        self.freq[key] = f + 1
        self.freq_to_keys[f + 1].append((self.time, key))
        self.time += 1

    def _evict(self):
        # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —á–∞—Å—Ç–æ—Ç—É
        while self.min_freq not in self.freq_to_keys or not self.freq_to_keys[self.min_freq]:
            self.min_freq += 1

        # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
        while self.freq_to_keys[self.min_freq]:
            _, key = self.freq_to_keys[self.min_freq].pop(0)
            if key in self.cache and self.freq[key] == self.min_freq:
                del self.cache[key]
                del self.freq[key]
                return
```

**Redis LFU:**

```bash
maxmemory-policy allkeys-lfu

# LFU –≤ Redis –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π —Å—á—ë—Ç—á–∏–∫
# lfu-log-factor ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞—Ç—É—Ö–∞–Ω–∏—è —Å—á—ë—Ç—á–∏–∫–∞
# lfu-decay-time ‚Äî –≤—Ä–µ–º—è –º–µ–∂–¥—É –¥–µ–∫—Ä–µ–º–µ–Ω—Ç–∞–º–∏
```

### 3. FIFO (First In, First Out)

–£–¥–∞–ª—è–µ—Ç—Å—è —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç (–ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è).

```python
from collections import deque

class FIFOCache:
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}
        self.queue = deque()

    def get(self, key: str):
        return self.cache.get(key)

    def set(self, key: str, value):
        if key in self.cache:
            self.cache[key] = value
            return

        if len(self.cache) >= self.capacity:
            oldest = self.queue.popleft()
            del self.cache[oldest]

        self.cache[key] = value
        self.queue.append(key)
```

### 4. TTL (Time To Live)

–î–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è—é—Ç—Å—è –ø–æ—Å–ª–µ –∏—Å—Ç–µ—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∂–∏–∑–Ω–∏.

```python
import time
import threading

class TTLCache:
    def __init__(self):
        self.cache = {}  # key -> (value, expire_time)
        self.lock = threading.Lock()

        # –§–æ–Ω–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        self._start_cleanup()

    def set(self, key: str, value, ttl: int):
        expire_at = time.time() + ttl
        with self.lock:
            self.cache[key] = (value, expire_at)

    def get(self, key: str):
        with self.lock:
            if key not in self.cache:
                return None

            value, expire_at = self.cache[key]

            if time.time() > expire_at:
                del self.cache[key]
                return None

            return value

    def _cleanup(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç—ë–∫—à–∏—Ö –∫–ª—é—á–µ–π"""
        while True:
            time.sleep(60)  # –ö–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
            now = time.time()
            with self.lock:
                expired = [k for k, (_, exp) in self.cache.items() if now > exp]
                for key in expired:
                    del self.cache[key]

    def _start_cleanup(self):
        thread = threading.Thread(target=self._cleanup, daemon=True)
        thread.start()
```

**Redis TTL:**

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ TTL
SET user:123 "data" EX 3600       # 1 —á–∞—Å
SETEX user:123 3600 "data"        # –¢–æ –∂–µ —Å–∞–º–æ–µ
PSETEX user:123 3600000 "data"    # –í –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏
TTL user:123      # –í —Å–µ–∫—É–Ω–¥–∞—Ö
PTTL user:123     # –í –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

# –£–¥–∞–ª–µ–Ω–∏–µ TTL
PERSIST user:123

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ TTL
EXPIRE user:123 7200    # –ù–æ–≤—ã–π TTL ‚Äî 2 —á–∞—Å–∞
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫

| –ü–æ–ª–∏—Ç–∏–∫–∞ | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|----------|-----------|-------------------|
| LRU | O(1) —Å OrderedDict | –û–±—â–∏–π —Å–ª—É—á–∞–π, —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –Ω–∞–≥—Ä—É–∑–æ–∫ |
| LFU | O(log n) | –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞, –∞ –Ω–µ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞ |
| FIFO | O(1) | –ü—Ä–æ—Å—Ç—ã–µ —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –ø–æ—Ä—è–¥–æ–∫ –¥–æ—Å—Ç—É–ø–∞ –Ω–µ –≤–∞–∂–µ–Ω |
| TTL | O(1) | –î–∞–Ω–Ω—ã–µ —Å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º –∂–∏–∑–Ω–∏ (—Å–µ—Å—Å–∏–∏, —Ç–æ–∫–µ–Ω—ã) |

---

## –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

### 1. Redis

–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ in-memory —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö.

**–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**

```bash
# –°—Ç—Ä–æ–∫–∏
SET user:123 '{"name":"John"}'
GET user:123

# Hash ‚Äî –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤
HSET user:123 name "John" age 30 email "john@example.com"
HGET user:123 name
HGETALL user:123

# –°–ø–∏—Å–∫–∏ ‚Äî –¥–ª—è –æ—á–µ—Ä–µ–¥–µ–π
LPUSH queue:tasks "task1"
RPOP queue:tasks

# Sets ‚Äî –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
SADD online:users "user1" "user2"
SMEMBERS online:users

# Sorted Sets ‚Äî –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
ZADD leaderboard 100 "player1" 200 "player2"
ZRANGE leaderboard 0 -1 WITHSCORES

# Pub/Sub ‚Äî –¥–ª—è —Å–æ–±—ã—Ç–∏–π
SUBSCRIBE channel
PUBLISH channel "message"
```

**–ü—Ä–∏–º–µ—Ä —Å Python:**

```python
import redis
from redis import Redis
from typing import Optional
import json

class RedisCache:
    def __init__(self, host='localhost', port=6379, db=0):
        self.client = Redis(
            host=host,
            port=port,
            db=db,
            decode_responses=True,
            socket_timeout=5,
            socket_connect_timeout=5
        )
        self.default_ttl = 3600

    def get(self, key: str) -> Optional[dict]:
        data = self.client.get(key)
        return json.loads(data) if data else None

    def set(self, key: str, value: dict, ttl: int = None):
        self.client.setex(
            key,
            ttl or self.default_ttl,
            json.dumps(value)
        )

    def delete(self, key: str):
        self.client.delete(key)

    def exists(self, key: str) -> bool:
        return self.client.exists(key) > 0

    def increment(self, key: str, amount: int = 1) -> int:
        return self.client.incrby(key, amount)

    def get_or_set(self, key: str, loader, ttl: int = None):
        """–ê—Ç–æ–º–∞—Ä–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞"""
        data = self.get(key)
        if data is None:
            data = loader()
            self.set(key, data, ttl)
        return data

    def mget(self, keys: list) -> dict:
        """Batch –ø–æ–ª—É—á–µ–Ω–∏–µ"""
        values = self.client.mget(keys)
        return {
            k: json.loads(v) if v else None
            for k, v in zip(keys, values)
        }

    def mset(self, data: dict, ttl: int = None):
        """Batch —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å TTL —á–µ—Ä–µ–∑ pipeline"""
        pipe = self.client.pipeline()
        for key, value in data.items():
            pipe.setex(key, ttl or self.default_ttl, json.dumps(value))
        pipe.execute()
```

**Redis Cluster:**

```python
from redis.cluster import RedisCluster

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–ª–∞—Å—Ç–µ—Ä—É
cluster = RedisCluster(
    startup_nodes=[
        {"host": "node1", "port": 7000},
        {"host": "node2", "port": 7001},
        {"host": "node3", "port": 7002},
    ]
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞–∫ –æ–±—ã—á–Ω–æ–≥–æ Redis
cluster.set("key", "value")
cluster.get("key")
```

### 2. Memcached

–ü—Ä–æ—Å—Ç–æ–π, –±—ã—Å—Ç—Ä—ã–π –∫—ç—à –¥–ª—è —Å—Ç—Ä–æ–∫ –∏ –æ–±—ä–µ–∫—Ç–æ–≤.

```python
import pylibmc
import json

class MemcachedCache:
    def __init__(self, servers=['localhost:11211']):
        self.client = pylibmc.Client(
            servers,
            behaviors={
                "tcp_nodelay": True,
                "ketama": True,  # Consistent hashing
                "connect_timeout": 1000,
                "send_timeout": 500000,
                "receive_timeout": 500000,
            }
        )

    def get(self, key: str):
        data = self.client.get(key)
        return json.loads(data) if data else None

    def set(self, key: str, value, ttl: int = 3600):
        self.client.set(key, json.dumps(value), time=ttl)

    def delete(self, key: str):
        self.client.delete(key)

    def get_multi(self, keys: list) -> dict:
        """Batch –ø–æ–ª—É—á–µ–Ω–∏–µ"""
        data = self.client.get_multi(keys)
        return {k: json.loads(v) for k, v in data.items()}

    def incr(self, key: str, delta: int = 1):
        return self.client.incr(key, delta)
```

### Redis vs Memcached

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | Redis | Memcached |
|---------------|-------|-----------|
| –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö | –ú–Ω–æ–≥–æ (strings, lists, sets, hashes, sorted sets) | –¢–æ–ª—å–∫–æ strings |
| –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å | –î–∞ (RDB, AOF) | –ù–µ—Ç |
| –†–µ–ø–ª–∏–∫–∞—Ü–∏—è | –î–∞ | –ù–µ—Ç (—Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏) |
| –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è | –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è | –ß–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ |
| Pub/Sub | –î–∞ | –ù–µ—Ç |
| Lua-—Å–∫—Ä–∏–ø—Ç—ã | –î–∞ | –ù–µ—Ç |
| –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ | –í—ã—à–µ | –ù–∏–∂–µ |
| Multi-threading | –ù–µ—Ç (–Ω–æ I/O threads –≤ 6.0+) | –î–∞ |

### 3. Varnish

HTTP-–∫—ç—à –¥–ª—è –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π (reverse proxy cache).

```vcl
# /etc/varnish/default.vcl

vcl 4.1;

backend default {
    .host = "127.0.0.1";
    .port = "8080";
}

sub vcl_recv {
    # –ù–µ –∫—ç—à–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã —Å –∫—É–∫–∞–º–∏
    if (req.http.Cookie) {
        return (pass);
    }

    # –ù–µ –∫—ç—à–∏—Ä—É–µ–º POST
    if (req.method != "GET" && req.method != "HEAD") {
        return (pass);
    }

    # –ö—ç—à–∏—Ä—É–µ–º API –Ω–∞ 5 –º–∏–Ω—É—Ç
    if (req.url ~ "^/api/") {
        return (hash);
    }

    return (hash);
}

sub vcl_backend_response {
    # –ö—ç—à–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏–∫—É –Ω–∞ 1 –¥–µ–Ω—å
    if (bereq.url ~ "\.(png|gif|jpg|js|css)$") {
        set beresp.ttl = 1d;
        set beresp.http.Cache-Control = "public, max-age=86400";
    }

    # API –∫—ç—à–∏—Ä—É–µ–º –Ω–∞ 5 –º–∏–Ω—É—Ç
    if (bereq.url ~ "^/api/") {
        set beresp.ttl = 5m;
    }

    return (deliver);
}

sub vcl_deliver {
    # –î–æ–±–∞–≤–ª—è–µ–º debug-–∑–∞–≥–æ–ª–æ–≤–∫–∏
    if (obj.hits > 0) {
        set resp.http.X-Cache = "HIT";
        set resp.http.X-Cache-Hits = obj.hits;
    } else {
        set resp.http.X-Cache = "MISS";
    }
}
```

### 4. CDN (Cloudflare, Akamai, Fastly)

**Cloudflare Cache Rules (–ø—Ä–∏–º–µ—Ä):**

```yaml
# –ü—Ä–∞–≤–∏–ª–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
rules:
  - name: "Cache API responses"
    expression: "(http.request.uri.path matches \"^/api/v1/products\")"
    action:
      cache:
        eligible: true
        edge_ttl: 3600
        browser_ttl: 300
        cache_key:
          query_string:
            include: ["category", "page"]

  - name: "Cache static assets"
    expression: "(http.request.uri.path matches \"\\.(js|css|png|jpg|woff2)$\")"
    action:
      cache:
        eligible: true
        edge_ttl: 31536000
        browser_ttl: 31536000
```

**–ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è CDN:**

```nginx
# nginx.conf

location /api/ {
    # Cloudflare-specific
    add_header CDN-Cache-Control "max-age=3600";

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Cache-Control
    add_header Cache-Control "public, max-age=300, s-maxage=3600";

    # Vary ‚Äî –∫—ç—à –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —ç—Ç–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    add_header Vary "Accept, Accept-Encoding, Authorization";

    # Surrogate-Control –¥–ª—è Varnish/Fastly
    add_header Surrogate-Control "max-age=3600";
}
```

---

## –ü—Ä–æ–±–ª–µ–º—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

### 1. Cache Invalidation

> "There are only two hard things in Computer Science: cache invalidation and naming things."
> ‚Äî Phil Karlton

**–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏:**

```python
class CacheInvalidation:
    def __init__(self, cache, db):
        self.cache = cache
        self.db = db

    # 1. TTL-based ‚Äî —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π
    def set_with_ttl(self, key: str, value, ttl: int = 300):
        self.cache.set(key, value, ttl=ttl)

    # 2. Event-based ‚Äî –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    def update_user(self, user_id: int, data: dict):
        self.db.update_user(user_id, data)

        # –£–¥–∞–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏
        self.cache.delete(f"user:{user_id}")
        self.cache.delete(f"user_profile:{user_id}")
        self.cache.delete(f"user_permissions:{user_id}")

    # 3. Versioned keys ‚Äî –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    def get_user_v(self, user_id: int):
        version = self.cache.get(f"user_version:{user_id}") or "1"
        return self.cache.get(f"user:{user_id}:v{version}")

    def invalidate_user(self, user_id: int):
        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º –≤–µ—Ä—Å–∏—é ‚Äî —Å—Ç–∞—Ä—ã–π –∫—ç—à –ø—Ä–æ—Å—Ç–æ –Ω–µ –Ω–∞–π–¥—ë—Ç—Å—è
        self.cache.incr(f"user_version:{user_id}")

    # 4. Tag-based ‚Äî –≥—Ä—É–ø–ø–æ–≤–∞—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è
    def set_with_tags(self, key: str, value, tags: list):
        self.cache.set(key, value)
        for tag in tags:
            self.cache.sadd(f"tag:{tag}", key)

    def invalidate_by_tag(self, tag: str):
        keys = self.cache.smembers(f"tag:{tag}")
        if keys:
            self.cache.delete(*keys)
            self.cache.delete(f"tag:{tag}")

# –ü—Ä–∏–º–µ—Ä tag-based –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏
cache = CacheInvalidation(redis_client, db)

# –ö—ç—à–∏—Ä—É–µ–º —Å —Ç–µ–≥–∞–º–∏
cache.set_with_tags("product:123", product_data, ["products", "category:electronics"])
cache.set_with_tags("product:456", product_data, ["products", "category:electronics"])

# –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
cache.invalidate_by_tag("category:electronics")
```

### 2. Cache Stampede (Thundering Herd)

–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏–¥—É—Ç –≤ –ë–î –ø—Ä–∏ –∏—Å—Ç–µ—á–µ–Ω–∏–∏ –∫—ç—à–∞.

```
TTL –∏—Å—Ç—ë–∫
     ‚îÇ
     ‚ñº
[Request 1] ‚îÄ‚îÄ‚îÄ‚îê
[Request 2] ‚îÄ‚îÄ‚îÄ‚î§
[Request 3] ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ [Database] üí• –ü–µ—Ä–µ–≥—Ä—É–∑–∫–∞!
[Request 4] ‚îÄ‚îÄ‚îÄ‚î§
[Request 5] ‚îÄ‚îÄ‚îÄ‚îò
```

**–†–µ—à–µ–Ω–∏—è:**

```python
import threading
import time
import hashlib

class AntiStampede:
    def __init__(self, cache, db):
        self.cache = cache
        self.db = db
        self.locks = {}
        self._lock = threading.Lock()

    # 1. Locking ‚Äî —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∏–¥—ë—Ç –≤ –ë–î
    def get_with_lock(self, key: str, loader, ttl: int = 300):
        value = self.cache.get(key)
        if value:
            return value

        lock_key = f"lock:{key}"

        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –ª–æ–∫
        if self.cache.set(lock_key, "1", nx=True, ex=10):
            try:
                # –ú—ã –ø–æ–ª—É—á–∏–ª–∏ –ª–æ–∫ ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                value = loader()
                self.cache.set(key, value, ttl=ttl)
                return value
            finally:
                self.cache.delete(lock_key)
        else:
            # –õ–æ–∫ –∑–∞–Ω—è—Ç ‚Äî –∂–¥—ë–º –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º
            time.sleep(0.1)
            return self.get_with_lock(key, loader, ttl)

    # 2. Probabilistic early expiration
    def get_with_early_recompute(self, key: str, loader, ttl: int = 300, beta: float = 1.0):
        """
        XFetch algorithm: —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è TTL
        """
        data = self.cache.get_with_metadata(key)

        if data is None:
            value = loader()
            self.cache.set(key, value, ttl=ttl)
            return value

        value, expiry, created = data
        now = time.time()
        remaining = expiry - now
        age = now - created

        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞–Ω–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ç—ë—Ç —Å –≤–æ–∑—Ä–∞—Å—Ç–æ–º
        # gap = ttl * beta * log(random())
        import random
        import math

        delta = ttl - remaining
        should_recompute = delta * beta * math.log(random.random()) >= remaining

        if should_recompute:
            value = loader()
            self.cache.set(key, value, ttl=ttl)

        return value

    # 3. Background refresh
    def get_with_background_refresh(self, key: str, loader, ttl: int = 300):
        value = self.cache.get(key)
        remaining_ttl = self.cache.ttl(key)

        if value:
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º –≤ —Ñ–æ–Ω–µ
            if remaining_ttl < ttl * 0.2:  # –ú–µ–Ω–µ–µ 20% TTL
                self._async_refresh(key, loader, ttl)
            return value

        # Cache miss
        value = loader()
        self.cache.set(key, value, ttl=ttl)
        return value

    def _async_refresh(self, key: str, loader, ttl: int):
        def refresh():
            value = loader()
            self.cache.set(key, value, ttl=ttl)

        thread = threading.Thread(target=refresh)
        thread.start()
```

### 3. Cache Penetration

–ó–∞–ø—Ä–æ—Å—ã –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤—Å–µ–≥–¥–∞ –∏–¥—É—Ç –≤ –ë–î.

```
–ê—Ç–∞–∫—É—é—â–∏–π –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç user_id=-1, -2, -3...
–¢–∞–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–µ—Ç ‚Üí –≤—Å–µ–≥–¥–∞ cache miss ‚Üí –ë–î –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞
```

**–†–µ—à–µ–Ω–∏—è:**

```python
class CachePenetrationProtection:
    def __init__(self, cache, db):
        self.cache = cache
        self.db = db

    # 1. –ö—ç—à–∏—Ä—É–µ–º null-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    def get_user(self, user_id: int):
        cache_key = f"user:{user_id}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –∫—ç—à–µ (–≤–∫–ª—é—á–∞—è null)
        cached = self.cache.get(cache_key)
        if cached == "NULL":
            return None
        if cached:
            return cached

        # –ó–∞–ø—Ä–æ—Å –∫ –ë–î
        user = self.db.get_user(user_id)

        if user:
            self.cache.set(cache_key, user, ttl=3600)
        else:
            # –ö—ç—à–∏—Ä—É–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ—Ä–æ—Ç–∫–∏–º TTL
            self.cache.set(cache_key, "NULL", ttl=60)

        return user

    # 2. Bloom Filter ‚Äî –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è
    def get_user_with_bloom(self, user_id: int):
        # Bloom filter –≥–æ–≤–æ—Ä–∏—Ç:
        # "—Ç–æ—á–Ω–æ –Ω–µ—Ç" –∏–ª–∏ "–≤–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å"
        if not self.bloom_filter.might_contain(f"user:{user_id}"):
            return None  # –¢–æ—á–Ω–æ –Ω–µ—Ç –≤ –ë–î

        # –í–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –∏ –ë–î
        return self.get_user(user_id)

    # 3. Rate limiting –¥–ª—è –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    def get_user_protected(self, user_id: int, client_ip: str):
        # –õ–∏–º–∏—Ç –Ω–∞ miss-—ã —Å –æ–¥–Ω–æ–≥–æ IP
        miss_key = f"misses:{client_ip}"
        misses = self.cache.incr(miss_key)

        if misses == 1:
            self.cache.expire(miss_key, 60)

        if misses > 100:  # –ë–æ–ª—å—à–µ 100 miss-–æ–≤ –≤ –º–∏–Ω—É—Ç—É
            raise RateLimitError("Too many cache misses")

        return self.get_user(user_id)
```

**Bloom Filter –ø—Ä–∏–º–µ—Ä:**

```python
import mmh3
from bitarray import bitarray

class BloomFilter:
    def __init__(self, size: int = 1000000, hash_count: int = 7):
        self.size = size
        self.hash_count = hash_count
        self.bit_array = bitarray(size)
        self.bit_array.setall(0)

    def add(self, item: str):
        for seed in range(self.hash_count):
            index = mmh3.hash(item, seed) % self.size
            self.bit_array[index] = 1

    def might_contain(self, item: str) -> bool:
        for seed in range(self.hash_count):
            index = mmh3.hash(item, seed) % self.size
            if not self.bit_array[index]:
                return False  # –¢–æ—á–Ω–æ –Ω–µ—Ç
        return True  # –í–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å (–º–æ–∂–µ—Ç –±—ã—Ç—å false positive)

# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
bloom = BloomFilter(size=10_000_000, hash_count=7)
for user_id in db.get_all_user_ids():
    bloom.add(f"user:{user_id}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
def get_user(user_id: int):
    if not bloom.might_contain(f"user:{user_id}"):
        return None  # –ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ø–æ—Ö–æ–¥–∞ –≤ –ë–î/–∫—ç—à

    # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å –∫—ç—à–µ–º
    ...
```

### 4. Cache Avalanche

–ú–∞—Å—Å–æ–≤–æ–µ –∏—Å—Ç–µ—á–µ–Ω–∏–µ TTL –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –ª–∞–≤–∏–Ω–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –ë–î.

```
12:00:00 ‚Äî –≤—Å–µ –∫–ª—é—á–∏ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã —Å TTL=1h
13:00:00 ‚Äî –≤—Å–µ –∫–ª—é—á–∏ –∏—Å—Ç–µ–∫–∞—é—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
         ‚Üí 10000 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –ë–î ‚Üí üí•
```

**–†–µ—à–µ–Ω–∏—è:**

```python
import random

class CacheAvalancheProtection:
    def __init__(self, cache):
        self.cache = cache

    # 1. –°–ª—É—á–∞–π–Ω—ã–π jitter –≤ TTL
    def set_with_jitter(self, key: str, value, base_ttl: int = 3600):
        # TTL = base_ttl ¬± 10%
        jitter = int(base_ttl * 0.1)
        actual_ttl = base_ttl + random.randint(-jitter, jitter)
        self.cache.set(key, value, ttl=actual_ttl)

    # 2. –†–∞–∑–Ω—ã–µ TTL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    def set_user(self, user_id: int, data: dict):
        self.set_with_jitter(f"user:{user_id}", data, base_ttl=3600)

    def set_product(self, product_id: int, data: dict):
        self.set_with_jitter(f"product:{product_id}", data, base_ttl=7200)

    # 3. –ü—Ä–æ–≥—Ä–µ–≤ –∫—ç—à–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (—Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º)
    async def warm_cache(self, items: list, base_ttl: int = 3600):
        for i, item in enumerate(items):
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º TTL, —á—Ç–æ–±—ã –Ω–µ –∏—Å—Ç–µ–∫–∞–ª–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
            offset = (i / len(items)) * base_ttl * 0.5  # 0-50% –æ—Ç TTL
            ttl = int(base_ttl + offset)
            await self.cache.set(item['key'], item['value'], ttl=ttl)
```

### 5. Consistency (–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å)

–î–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î.

```python
class ConsistencyStrategies:
    def __init__(self, cache, db):
        self.cache = cache
        self.db = db

    # 1. Strong consistency ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    def update_user_strong(self, user_id: int, data: dict):
        # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
        try:
            self.db.begin()
            self.db.update_user(user_id, data)
            self.cache.delete(f"user:{user_id}")
            self.db.commit()
        except Exception:
            self.db.rollback()
            raise

    # 2. Eventual consistency ‚Äî –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–æ–±—ã—Ç–∏—è
    async def update_user_eventual(self, user_id: int, data: dict):
        self.db.update_user(user_id, data)

        # –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ
        await self.event_bus.publish("user.updated", {
            "user_id": user_id,
            "timestamp": time.time()
        })

    async def handle_user_updated(self, event: dict):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏—è ‚Äî –∏–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫—ç—à"""
        user_id = event["user_id"]
        self.cache.delete(f"user:{user_id}")

    # 3. Read-your-writes ‚Äî –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–∏—Ç —Å–≤–æ–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    def get_user_with_ryw(self, user_id: int, session_writes: dict):
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ–ª—å–∫–æ —á—Ç–æ –æ–±–Ω–æ–≤–∏–ª –¥–∞–Ω–Ω—ã–µ
        if f"user:{user_id}" in session_writes:
            # –ß–∏—Ç–∞–µ–º –∏–∑ –ë–î, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –∫—ç—à
            return self.db.get_user(user_id)

        # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å –∫—ç—à–µ–º
        return self.get_user(user_id)

    def update_user_with_ryw(self, user_id: int, data: dict, session_writes: dict):
        self.db.update_user(user_id, data)
        self.cache.delete(f"user:{user_id}")

        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤ —Å–µ—Å—Å–∏–∏
        session_writes[f"user:{user_id}"] = time.time()
```

---

## –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (Distributed Caching)

### –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ

```
                    Hash Ring
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚ï±             ‚ï≤
               ‚ï±                 ‚ï≤
              ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
              ‚îÇ    ‚îÇ N1‚îÇ         ‚îÇ
             ‚ï±     ‚îî‚îÄ‚îÄ‚îÄ‚îò          ‚ï≤
            ‚îÇ                      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚î§                      ‚îú‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ N4‚îÇ                      ‚îÇ N2‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚î§                      ‚îú‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                      ‚îÇ
             ‚ï≤     ‚îå‚îÄ‚îÄ‚îÄ‚îê          ‚ï±
              ‚îÇ    ‚îÇ N3‚îÇ         ‚îÇ
              ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
               ‚ï≤                 ‚ï±
                 ‚ï≤             ‚ï±
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–ö–ª—é—á "user:123" ‚Üí hash ‚Üí –ø–æ–ø–∞–¥–∞–µ—Ç –Ω–∞ N2
–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ N5 –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º –∫–ª—é—á–µ–π
```

```python
import hashlib
from bisect import bisect_left

class ConsistentHash:
    def __init__(self, nodes: list = None, virtual_nodes: int = 100):
        self.virtual_nodes = virtual_nodes
        self.ring = {}
        self.sorted_keys = []

        if nodes:
            for node in nodes:
                self.add_node(node)

    def _hash(self, key: str) -> int:
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def add_node(self, node: str):
        """–î–æ–±–∞–≤–ª—è–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —É–∑–ª—ã –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node
            self.sorted_keys.append(hash_value)

        self.sorted_keys.sort()

    def remove_node(self, node: str):
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            del self.ring[hash_value]
            self.sorted_keys.remove(hash_value)

    def get_node(self, key: str) -> str:
        if not self.ring:
            return None

        hash_value = self._hash(key)

        # –ò—â–µ–º –ø–µ—Ä–≤—ã–π —É–∑–µ–ª –ø–æ —á–∞—Å–æ–≤–æ–π —Å—Ç—Ä–µ–ª–∫–µ
        idx = bisect_left(self.sorted_keys, hash_value)
        if idx == len(self.sorted_keys):
            idx = 0

        return self.ring[self.sorted_keys[idx]]

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
ring = ConsistentHash(["redis-1", "redis-2", "redis-3"])

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω–∞ –∫–∞–∫–æ–π —É–∑–µ–ª –∏–¥—ë—Ç –∑–∞–ø—Ä–æ—Å
node = ring.get_node("user:123")  # ‚Üí "redis-2"

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —É–∑–ª–∞ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–∏–Ω–∏–º—É–º –∫–ª—é—á–µ–π
ring.add_node("redis-4")
```

### –†–µ–ø–ª–∏–∫–∞—Ü–∏—è –∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
class DistributedCache:
    def __init__(self, nodes: list, replicas: int = 2):
        self.consistent_hash = ConsistentHash(nodes)
        self.replicas = replicas
        self.connections = {node: Redis(node) for node in nodes}

    def _get_nodes(self, key: str) -> list:
        """–ü–æ–ª—É—á–∞–µ–º primary –∏ replica —É–∑–ª—ã"""
        primary = self.consistent_hash.get_node(key)
        nodes = [primary]

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ø–ª–∏–∫–∏
        idx = self.consistent_hash.sorted_keys.index(
            self.consistent_hash._hash(f"{primary}:0")
        )

        while len(nodes) < self.replicas + 1:
            idx = (idx + 1) % len(self.consistent_hash.sorted_keys)
            node = self.consistent_hash.ring[self.consistent_hash.sorted_keys[idx]]
            if node not in nodes:
                nodes.append(node)

        return nodes

    def get(self, key: str):
        """–ß–∏—Ç–∞–µ–º —Å –ª—é–±–æ–π —Ä–µ–ø–ª–∏–∫–∏"""
        nodes = self._get_nodes(key)

        for node in nodes:
            try:
                value = self.connections[node].get(key)
                if value:
                    return value
            except ConnectionError:
                continue

        return None

    def set(self, key: str, value, ttl: int = 3600):
        """–ü–∏—à–µ–º –Ω–∞ –≤—Å–µ —Ä–µ–ø–ª–∏–∫–∏"""
        nodes = self._get_nodes(key)

        for node in nodes:
            try:
                self.connections[node].setex(key, ttl, value)
            except ConnectionError:
                # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                pass
```

### Redis Cluster

```python
from redis.cluster import RedisCluster

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—è
cluster = RedisCluster(
    startup_nodes=[
        {"host": "redis-1", "port": 7000},
        {"host": "redis-2", "port": 7001},
        {"host": "redis-3", "port": 7002},
    ],
    decode_responses=True,
    skip_full_coverage_check=True
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞–∫ –æ–±—ã—á–Ω–æ–≥–æ Redis
cluster.set("user:123", "data")
cluster.get("user:123")

# –î–ª—è –∞—Ç–æ–º–∞—Ä–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–ª—é—á–∞–º–∏
# –∏—Å–ø–æ–ª—å–∑—É–µ–º hash tags ‚Äî –∫–ª—é—á–∏ –Ω–∞ –æ–¥–Ω–æ–º —Å–ª–æ—Ç–µ
cluster.set("{user:123}:profile", "...")
cluster.set("{user:123}:settings", "...")

# Pipeline –¥–ª—è batch-–æ–ø–µ—Ä–∞—Ü–∏–π
pipe = cluster.pipeline()
pipe.get("key1")
pipe.get("key2")
results = pipe.execute()
```

---

## Best Practices

### 1. –ò–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–π

```python
# –•–æ—Ä–æ—à–æ ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
"user:123:profile"
"user:123:orders"
"product:456:details"
"session:abc123"

# –ü–ª–æ—Ö–æ ‚Äî –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏
"u123p"
"mydata"
"temp"
```

### 2. –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è

```python
import json
import pickle
import msgpack

# JSON ‚Äî —á–∏—Ç–∞–µ–º—ã–π, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π
data = json.dumps({"name": "John", "age": 30})

# MessagePack ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, –±—ã—Å—Ç—Ä—ã–π
data = msgpack.packb({"name": "John", "age": 30})

# Pickle ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è Python, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
data = pickle.dumps(complex_object)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
obj = {"users": [{"id": i, "name": f"User {i}"} for i in range(100)]}
len(json.dumps(obj))      # ~3800 bytes
len(msgpack.packb(obj))   # ~2400 bytes
```

### 3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

```python
import time
from datadog import statsd

class MonitoredCache:
    def __init__(self, cache):
        self.cache = cache

    def get(self, key: str):
        start = time.time()
        value = self.cache.get(key)
        duration = time.time() - start

        # –ú–µ—Ç—Ä–∏–∫–∏
        statsd.timing("cache.get.latency", duration * 1000)
        statsd.increment("cache.get.total")

        if value:
            statsd.increment("cache.hit")
        else:
            statsd.increment("cache.miss")

        return value

    def set(self, key: str, value, ttl: int = 3600):
        start = time.time()
        self.cache.set(key, value, ttl=ttl)
        duration = time.time() - start

        statsd.timing("cache.set.latency", duration * 1000)
        statsd.increment("cache.set.total")
        statsd.gauge("cache.key.ttl", ttl, tags=[f"key:{key}"])
```

**Redis –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:**

```bash
# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
redis-cli INFO stats
redis-cli INFO memory

# –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
# - keyspace_hits / keyspace_misses ‚Üí hit ratio
# - used_memory / maxmemory ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
# - evicted_keys ‚Üí –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ç–µ—Å–Ω–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π
# - connected_clients ‚Üí –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

# Slowlog
redis-cli SLOWLOG GET 10

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
redis-cli MONITOR
```

### 4. Graceful Degradation

```python
class ResilientCache:
    def __init__(self, cache, db):
        self.cache = cache
        self.db = db
        self.cache_available = True

    def get(self, key: str, loader):
        if not self.cache_available:
            return loader()

        try:
            value = self.cache.get(key)
            if value:
                return value

            data = loader()
            self.cache.set(key, data)
            return data

        except ConnectionError:
            self.cache_available = False
            self._schedule_health_check()
            return loader()

    def _schedule_health_check(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫—ç—à–∞"""
        async def check():
            while not self.cache_available:
                await asyncio.sleep(5)
                try:
                    self.cache.ping()
                    self.cache_available = True
                except ConnectionError:
                    pass

        asyncio.create_task(check())
```

### 5. –†–∞–∑–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏–π

```python
# –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
MAX_CACHE_VALUE_SIZE = 1024 * 1024  # 1MB

def set_safe(cache, key: str, value, ttl: int = 3600):
    serialized = json.dumps(value)

    if len(serialized) > MAX_CACHE_VALUE_SIZE:
        # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –æ–±—ä–µ–∫—Ç ‚Äî –Ω–µ –∫—ç—à–∏—Ä—É–µ–º
        logger.warning(f"Value too large to cache: {key}, size: {len(serialized)}")
        return False

    cache.set(key, serialized, ttl=ttl)
    return True

# –î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ ‚Äî –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
import gzip

def set_compressed(cache, key: str, value, ttl: int = 3600):
    serialized = json.dumps(value).encode()
    compressed = gzip.compress(serialized)

    cache.set(key, compressed, ttl=ttl)

def get_compressed(cache, key: str):
    compressed = cache.get(key)
    if compressed:
        decompressed = gzip.decompress(compressed)
        return json.loads(decompressed)
    return None
```

---

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### 1. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ API-–æ—Ç–≤–µ—Ç–æ–≤

```python
from fastapi import FastAPI, Request
from functools import wraps
import hashlib
import json

app = FastAPI()

def cache_response(ttl: int = 300):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            request: Request = kwargs.get('request') or args[0]
            cache_key = f"api:{request.url.path}:{request.query_params}"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached = redis.get(cache_key)
            if cached:
                return json.loads(cached)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            result = await func(*args, **kwargs)

            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            redis.setex(cache_key, ttl, json.dumps(result))

            return result
        return wrapper
    return decorator

@app.get("/api/products")
@cache_response(ttl=300)
async def get_products(category: str = None):
    products = await db.get_products(category)
    return {"products": products}
```

### 2. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–π

```python
from fastapi import FastAPI, Depends, HTTPException
from fastapi.security import HTTPBearer
import secrets

class SessionStore:
    def __init__(self, redis_client, ttl: int = 86400):
        self.redis = redis_client
        self.ttl = ttl

    def create_session(self, user_id: int, data: dict = None) -> str:
        session_id = secrets.token_urlsafe(32)
        session_data = {
            "user_id": user_id,
            "created_at": time.time(),
            **(data or {})
        }

        self.redis.setex(
            f"session:{session_id}",
            self.ttl,
            json.dumps(session_data)
        )

        return session_id

    def get_session(self, session_id: str) -> dict:
        data = self.redis.get(f"session:{session_id}")
        if not data:
            return None

        # –ü—Ä–æ–¥–ª–µ–≤–∞–µ–º TTL –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏
        self.redis.expire(f"session:{session_id}", self.ttl)

        return json.loads(data)

    def destroy_session(self, session_id: str):
        self.redis.delete(f"session:{session_id}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
session_store = SessionStore(redis)

@app.post("/login")
async def login(credentials: LoginRequest):
    user = await authenticate(credentials)
    session_id = session_store.create_session(user.id)
    return {"session_id": session_id}

async def get_current_user(token: str = Depends(HTTPBearer())):
    session = session_store.get_session(token.credentials)
    if not session:
        raise HTTPException(401, "Invalid session")
    return session
```

### 3. Rate Limiting

```python
class RateLimiter:
    def __init__(self, redis_client):
        self.redis = redis_client

    def is_allowed(self, key: str, limit: int, window: int) -> tuple[bool, int]:
        """
        Sliding window rate limiter

        Args:
            key: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (IP, user_id)
            limit: –º–∞–∫—Å–∏–º—É–º –∑–∞–ø—Ä–æ—Å–æ–≤
            window: –æ–∫–Ω–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            (allowed, remaining)
        """
        now = time.time()
        window_start = now - window

        pipe = self.redis.pipeline()

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
        pipe.zremrangebyscore(key, 0, window_start)

        # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        pipe.zcard(key)

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        pipe.zadd(key, {str(now): now})

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TTL
        pipe.expire(key, window)

        results = pipe.execute()
        current_count = results[1]

        if current_count >= limit:
            return False, 0

        return True, limit - current_count - 1

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
limiter = RateLimiter(redis)

@app.middleware("http")
async def rate_limit_middleware(request: Request, call_next):
    client_ip = request.client.host

    allowed, remaining = limiter.is_allowed(
        f"rate:{client_ip}",
        limit=100,
        window=60
    )

    if not allowed:
        return JSONResponse(
            {"error": "Too many requests"},
            status_code=429,
            headers={"Retry-After": "60"}
        )

    response = await call_next(request)
    response.headers["X-RateLimit-Remaining"] = str(remaining)
    return response
```

### 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞

```python
import uuid
import time

class DistributedLock:
    def __init__(self, redis_client, name: str, timeout: int = 10):
        self.redis = redis_client
        self.name = f"lock:{name}"
        self.timeout = timeout
        self.token = str(uuid.uuid4())

    def acquire(self) -> bool:
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫—É"""
        return self.redis.set(
            self.name,
            self.token,
            nx=True,  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            ex=self.timeout
        )

    def release(self) -> bool:
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ (–∞—Ç–æ–º–∞—Ä–Ω–æ)"""
        script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        return self.redis.eval(script, 1, self.name, self.token)

    def __enter__(self):
        acquired = self.acquire()
        if not acquired:
            raise LockError(f"Could not acquire lock: {self.name}")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
def process_order(order_id: int):
    with DistributedLock(redis, f"order:{order_id}", timeout=30):
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–∫—Ü–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–æ—Ü–µ—Å—Å
        order = db.get_order(order_id)
        process(order)
        db.update_order(order_id, status="processed")
```

### 5. Leaderboard

```python
class Leaderboard:
    def __init__(self, redis_client, name: str):
        self.redis = redis_client
        self.key = f"leaderboard:{name}"

    def add_score(self, player_id: str, score: float):
        """–î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å —Å—á—ë—Ç –∏–≥—Ä–æ–∫–∞"""
        self.redis.zadd(self.key, {player_id: score})

    def increment_score(self, player_id: str, delta: float):
        """–£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç"""
        return self.redis.zincrby(self.key, delta, player_id)

    def get_rank(self, player_id: str) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Å—Ç–æ –∏–≥—Ä–æ–∫–∞ (0 = –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ)"""
        rank = self.redis.zrevrank(self.key, player_id)
        return rank + 1 if rank is not None else None

    def get_top(self, n: int = 10) -> list:
        """–¢–æ–ø N –∏–≥—Ä–æ–∫–æ–≤"""
        results = self.redis.zrevrange(
            self.key,
            0,
            n - 1,
            withscores=True
        )
        return [
            {"player_id": player, "score": score, "rank": i + 1}
            for i, (player, score) in enumerate(results)
        ]

    def get_around_player(self, player_id: str, n: int = 5) -> list:
        """–ò–≥—Ä–æ–∫–∏ –≤–æ–∫—Ä—É–≥ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ"""
        rank = self.redis.zrevrank(self.key, player_id)
        if rank is None:
            return []

        start = max(0, rank - n)
        end = rank + n

        results = self.redis.zrevrange(
            self.key,
            start,
            end,
            withscores=True
        )

        return [
            {"player_id": player, "score": score, "rank": start + i + 1}
            for i, (player, score) in enumerate(results)
        ]

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
leaderboard = Leaderboard(redis, "weekly")

leaderboard.add_score("player1", 1000)
leaderboard.increment_score("player1", 50)

top10 = leaderboard.get_top(10)
my_rank = leaderboard.get_rank("player1")
nearby = leaderboard.get_around_player("player1", n=5)
```

---

## –ß–µ–∫-–ª–∏—Å—Ç –ø–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—é

### –ü—Ä–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏

- [ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å (read-heavy, expensive queries)
- [ ] –í—ã–±—Ä–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (cache-aside, read-through, etc.)
- [ ] –í—ã–±—Ä–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É –≤—ã—Ç–µ—Å–Ω–µ–Ω–∏—è (LRU, LFU, TTL)
- [ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å TTL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
- [ ] –°–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—é –∫—ç—à–∞
- [ ] –ü—Ä–æ–¥—É–º–∞—Ç—å graceful degradation

### –ü—Ä–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–π
- [ ] –î–æ–±–∞–≤–∏—Ç—å jitter –∫ TTL –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è avalanche
- [ ] –ó–∞—â–∏—Ç–∏—Ç—å—Å—è –æ—Ç cache stampede (locking, early recompute)
- [ ] –ó–∞—â–∏—Ç–∏—Ç—å—Å—è –æ—Ç cache penetration (null caching, bloom filter)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (hit ratio, latency, memory)
- [ ] –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å cache miss –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

### –ü—Ä–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏

- [ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å hit ratio (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å >90%)
- [ ] –°–ª–µ–¥–∏—Ç—å –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–∞–º—è—Ç–∏
- [ ] –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å slowlog
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏
- [ ] –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Ä–µ–≤—å—é–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

---

## –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

1. [Redis Documentation](https://redis.io/documentation)
2. [Memcached Wiki](https://github.com/memcached/memcached/wiki)
3. [Varnish Cache](https://varnish-cache.org/docs/)
4. [Cloudflare Cache](https://developers.cloudflare.com/cache/)
5. [Caching Strategies and How to Choose the Right One](https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/)
6. [System Design Primer - Caching](https://github.com/donnemartin/system-design-primer#cache)
