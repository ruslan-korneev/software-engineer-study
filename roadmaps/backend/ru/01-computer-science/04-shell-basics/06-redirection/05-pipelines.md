# Конвейеры (Pipelines)

## Что такое pipe (конвейер)?

**Pipe** (`|`) — оператор, который передаёт stdout одной команды на stdin другой. Это позволяет объединять простые команды в мощные цепочки обработки данных.

```
команда1 | команда2 | команда3
    ↓          ↓          ↓
  stdout → stdin    stdout → stdin
```

## Базовое использование

```bash
$ ls -la | less
# Вывод ls передаётся в less для постраничного просмотра

$ ps aux | grep python
# Список процессов фильтруется grep

$ cat file.txt | wc -l
# Подсчёт строк в файле
```

## Философия Unix

Pipe — воплощение философии Unix:
> Пишите программы, которые делают одну вещь хорошо.
> Пишите программы, которые работают вместе.

Каждая команда делает что-то одно, но вместе они решают сложные задачи.

## Практические примеры

### Поиск и фильтрация

```bash
# Найти процессы Python
$ ps aux | grep python

# Найти самые большие файлы
$ du -sh * | sort -rh | head -10

# Найти уникальные IP в логах
$ cat access.log | awk '{print $1}' | sort | uniq -c | sort -rn
```

### Обработка текста

```bash
# Подсчитать слова в файле
$ cat file.txt | wc -w

# Отсортировать и убрать дубликаты
$ cat names.txt | sort | uniq

# Первые 10 строк после сортировки
$ cat data.txt | sort | head -10
```

### Работа с данными

```bash
# Статистика по расширениям файлов
$ ls | rev | cut -d. -f1 | rev | sort | uniq -c | sort -rn

# Сумма чисел в файле
$ cat numbers.txt | paste -sd+ | bc

# Среднее значение
$ cat numbers.txt | awk '{sum+=$1; count++} END {print sum/count}'
```

## Полезные команды для конвейеров

### Фильтрация
| Команда | Назначение |
|---------|------------|
| `grep` | Фильтр по шаблону |
| `head` | Первые N строк |
| `tail` | Последние N строк |
| `uniq` | Убрать дубликаты (нужен sort) |

### Трансформация
| Команда | Назначение |
|---------|------------|
| `sort` | Сортировка |
| `cut` | Вырезать колонки |
| `awk` | Обработка полей |
| `sed` | Потоковое редактирование |
| `tr` | Замена символов |

### Статистика
| Команда | Назначение |
|---------|------------|
| `wc` | Подсчёт строк/слов/символов |
| `uniq -c` | Подсчёт вхождений |

## Команда tee

**tee** — разветвляет поток: выводит на экран И записывает в файл.

```bash
$ ls | tee listing.txt
file1
file2
file3
# Вывод на экран И запись в listing.txt

$ ls | tee listing.txt | wc -l
3
# Записывает в файл И передаёт дальше
```

С добавлением в файл:
```bash
$ echo "new data" | tee -a log.txt
```

## xargs — аргументы из stdin

**xargs** преобразует stdin в аргументы команды:

```bash
# Удалить все .tmp файлы
$ find . -name "*.tmp" | xargs rm

# С обработкой пробелов в именах
$ find . -name "*.tmp" -print0 | xargs -0 rm

# Выполнить команду для каждого элемента
$ cat urls.txt | xargs -I {} curl {}
```

## Многострочные конвейеры

Для читаемости можно разбивать на строки:

```bash
$ cat access.log \
    | grep "ERROR" \
    | awk '{print $1, $4}' \
    | sort \
    | uniq -c \
    | sort -rn \
    | head -10
```

## Обработка stderr в pipe

По умолчанию pipe передаёт только stdout:

```bash
$ command 2>&1 | grep "error"
# stderr объединён с stdout

$ command |& grep "error"
# То же самое (bash 4+)
```

## Статус выхода

По умолчанию статус выхода конвейера — статус последней команды:

```bash
$ false | true
$ echo $?
0                          # статус true (последняя команда)
```

Опция `pipefail` меняет поведение:
```bash
$ set -o pipefail
$ false | true
$ echo $?
1                          # статус false (первая неудачная)
```

## Именованные каналы (FIFO)

Для сложных сценариев можно создать именованный канал:

```bash
$ mkfifo mypipe

# Терминал 1:
$ cat > mypipe

# Терминал 2:
$ cat < mypipe
```

## Продвинутые примеры

### Мониторинг логов в реальном времени
```bash
$ tail -f /var/log/syslog | grep --line-buffered "error"
```

### Параллельная обработка
```bash
$ cat urls.txt | xargs -P 4 -I {} curl -O {}
# 4 параллельных загрузки
```

### Цепочка обработки CSV
```bash
$ cat data.csv \
    | tail -n +2 \              # убрать заголовок
    | cut -d',' -f2,4 \         # колонки 2 и 4
    | sort -t',' -k2 -n \       # сортировка по колонке 2
    | head -10
```

### Анализ истории команд
```bash
$ history | awk '{print $2}' | sort | uniq -c | sort -rn | head -10
# Топ-10 самых используемых команд
```

## Советы

1. **Стройте пошагово**: добавляйте команды по одной, проверяя результат
2. **Используйте head** на больших данных для тестирования
3. **Помните о grep -v** для исключения строк
4. **sort перед uniq** — uniq работает только с соседними строками
5. **xargs -I {}** для подстановки аргумента в середину команды
6. **Включите pipefail** в скриптах для надёжной обработки ошибок
