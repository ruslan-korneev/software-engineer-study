# Big Omega Notation (Ω-большое)

[prev: 02-big-o](./02-big-o.md) | [next: 04-big-theta](./04-big-theta.md)

---
## Определение

**Big Omega (Ω-большое)** — это математическая нотация, описывающая **нижнюю границу** роста функции. В контексте алгоритмов она показывает **минимальную** (best case) сложность алгоритма.

### Формальное определение

f(n) = Ω(g(n)) означает, что существуют константы c > 0 и n₀ ≥ 0 такие, что:

```
f(n) ≥ c · g(n)  для всех n ≥ n₀
```

Проще говоря: начиная с некоторого n₀, функция f(n) **не меньше** g(n), умноженной на константу.

## Зачем нужно

### Практическое применение

1. **Определение минимальных требований** — понять, быстрее какого предела алгоритм работать не может
2. **Теоретические доказательства** — показать, что задача требует минимум определённого числа операций
3. **Оптимальность алгоритма** — если Big O = Big Omega, алгоритм оптимален
4. **Нижняя граница задачи** — доказать, что никакой алгоритм не может решить задачу быстрее

### Сравнение с Big O

| Нотация | Описывает | Вопрос |
|---------|-----------|--------|
| Big O | Верхняя граница | "Как плохо может быть?" |
| Big Ω | Нижняя граница | "Как хорошо может быть?" |

### Пример понимания

Для сортировки сравнением:
- **Big O:** O(n log n) — не медленнее (худший случай)
- **Big Ω:** Ω(n log n) — не быстрее (лучший случай для любого алгоритма сортировки сравнением)

Это означает, что **невозможно** создать алгоритм сортировки сравнением быстрее O(n log n).

## Как работает

### Связь с Big O

Big Omega — это "зеркало" Big O:

```
f(n) = O(g(n))  ⟺  g(n) = Ω(f(n))
```

Если f растёт не быстрее g, то g растёт не медленнее f.

### Правила вычисления

Аналогичны Big O, но с обратным неравенством:

**1. Константы можно отбрасывать:**
```
Ω(2n) = Ω(n)
Ω(n/3) = Ω(n)
```

**2. Можно использовать меньшую функцию:**
```
n² = Ω(n)      — верно (n² всегда ≥ n при n ≥ 1)
n² = Ω(n²)    — верно
n² = Ω(n³)    — неверно (n² не всегда ≥ n³)
```

### Best Case vs Big Omega

Важно различать:
- **Best case** — лучший случай для конкретного алгоритма
- **Big Omega для задачи** — нижняя граница для ЛЮБОГО алгоритма, решающего задачу

## Визуализация

### Графическое представление Big Omega

```
f(n)
  ↑
  │         ╱ f(n) — наша функция
  │       ╱
  │     ╱
  │   ╱    -------- c·g(n) — нижняя граница
  │ ╱    --
  │╱  --╱
  │--╱
  │╱
  └─────────────────────→ n
      ↑
      n₀ (начиная отсюда f(n) ≥ c·g(n))
```

### Сравнение Big O и Big Omega

```
f(n)
  ↑
  │              ╱ c₁·g(n) — верхняя граница (Big O)
  │            ╱
  │          ╱  _____ f(n)
  │        ╱__-╱
  │      ╱╱
  │    ╱╱   -------- c₂·g(n) — нижняя граница (Big Ω)
  │  ╱╱  ---╱
  │╱╱---╱
  │╱
  └─────────────────────→ n
```

## Примеры с разбором

### Пример 1: Линейный поиск

```python
def linear_search(arr, target):
    for i, x in enumerate(arr):
        if x == target:
            return i
    return -1
```

**Анализ:**
- **Best case:** Ω(1) — элемент в начале
- **Worst case:** O(n) — элемент в конце или отсутствует
- **Big Omega алгоритма:** Ω(1)

### Пример 2: Поиск максимума

```python
def find_max(arr):
    max_val = arr[0]
    for x in arr:
        if x > max_val:
            max_val = x
    return max_val
```

**Анализ:**
- **Best case:** Ω(n) — нужно проверить все элементы
- **Worst case:** O(n) — проверяем все элементы
- **Big Omega = Big O = Θ(n)** — алгоритм оптимален

### Пример 3: Сортировка вставками

```python
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        while j >= 0 and arr[j] > key:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key
```

**Анализ:**
- **Best case:** Ω(n) — массив уже отсортирован
- **Worst case:** O(n²) — массив отсортирован в обратном порядке

### Пример 4: Нижняя граница сортировки сравнением

Любой алгоритм сортировки, использующий сравнения, имеет нижнюю границу Ω(n log n).

**Доказательство (упрощённо):**
- Есть n! возможных перестановок
- Каждое сравнение — бинарное решение
- Нужно минимум log₂(n!) сравнений
- log₂(n!) ≈ n log n (по формуле Стирлинга)

```
Дерево решений для 3 элементов:
                    a < b?
                   /     \
                  да      нет
                 /          \
            b < c?          a < c?
           /    \          /     \
         да     нет      да      нет
         ↓       ↓        ↓        ↓
       [a,b,c] a < c?  [b,a,c]  b < c?
               /  \            /    \
             да   нет        да     нет
              ↓    ↓          ↓       ↓
          [a,c,b][c,a,b]  [b,c,a] [c,b,a]

6 листьев = 3! перестановок
Глубина ≥ log₂(6) ≈ 2.58 → минимум 3 сравнения
```

### Пример 5: Поиск в хеш-таблице

```python
def hash_lookup(hash_table, key):
    index = hash(key) % len(hash_table)
    return hash_table[index]
```

**Анализ:**
- **Best case:** Ω(1) — нет коллизий
- **Worst case:** O(n) — все ключи в одной ячейке
- **Average case:** Θ(1) — равномерное распределение

## Примеры нижних границ задач

### Поиск в несортированном массиве

```
Нижняя граница: Ω(n)
```
Необходимо просмотреть все элементы, чтобы убедиться в отсутствии искомого.

### Поиск в сортированном массиве

```
Нижняя граница: Ω(log n)
```
Бинарный поиск достигает этой границы — оптимален.

### Умножение матриц

```
Известная нижняя граница: Ω(n²)
Лучший известный алгоритм: O(n^2.373)
```
Разрыв между границами — открытая проблема.

## Типичные ошибки

### 1. Путать best case с Big Omega

```python
# Линейный поиск
# Best case: Ω(1) — элемент первый
# Это НЕ означает, что алгоритм всегда работает за O(1)
```

### 2. Считать, что Big Omega всегда равно Big O

```python
# Сортировка вставками:
# Big O: O(n²)
# Big Ω: Ω(n)
# Они разные!

# Сортировка слиянием:
# Big O: O(n log n)
# Big Ω: Ω(n log n)
# Здесь равны
```

### 3. Забывать о контексте

```
"Поиск за Ω(1)" может означать:
- Best case конкретного алгоритма
- Нижняя граница задачи (если доказано)
- Амортизированная сложность
```

## Связь между нотациями

```
        Big O (верхняя граница)
             ↑
             │
    ┌────────┼────────┐
    │        │        │
    │    Big Θ       │
    │   (точная)     │
    │        │        │
    └────────┼────────┘
             │
             ↓
       Big Ω (нижняя граница)

Если f(n) = O(g(n)) и f(n) = Ω(g(n)), то f(n) = Θ(g(n))
```

## Резюме

- Big Omega описывает **нижнюю границу** (минимальное число операций)
- Отвечает на вопрос: "как хорошо может быть?"
- Важна для доказательства **оптимальности** алгоритмов
- Нижняя граница **задачи** отличается от best case **алгоритма**
- Если Big O = Big Ω, используем Big Θ (точная оценка)

---

[prev: 02-big-o](./02-big-o.md) | [next: 04-big-theta](./04-big-theta.md)
