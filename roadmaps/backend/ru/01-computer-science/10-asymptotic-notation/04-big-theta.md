# Big Theta Notation (Θ-большое)

[prev: 03-big-omega](./03-big-omega.md) | [next: 05-common-complexities](./05-common-complexities.md)

---
## Определение

**Big Theta (Θ-большое)** — это математическая нотация, описывающая **точную** асимптотическую сложность функции. Она задаёт и верхнюю, и нижнюю границу одновременно.

### Формальное определение

f(n) = Θ(g(n)) означает, что существуют константы c₁ > 0, c₂ > 0 и n₀ ≥ 0 такие, что:

```
c₁ · g(n) ≤ f(n) ≤ c₂ · g(n)  для всех n ≥ n₀
```

Проще говоря: f(n) растёт **с той же скоростью**, что и g(n).

### Эквивалентное определение

```
f(n) = Θ(g(n))  ⟺  f(n) = O(g(n)) И f(n) = Ω(g(n))
```

Big Theta — это пересечение Big O и Big Omega.

## Зачем нужно

### Практическое применение

1. **Точная характеристика** — когда алгоритм гарантированно работает с определённой скоростью
2. **Сравнение алгоритмов** — если оба Θ(n log n), они асимптотически эквивалентны
3. **Теоретический анализ** — доказательство, что алгоритм оптимален для задачи
4. **Предсказуемость** — знаем точное поведение, а не только границы

### Когда использовать какую нотацию

| Ситуация | Нотация | Пример |
|----------|---------|--------|
| Только верхняя граница | O | "Не медленнее O(n²)" |
| Только нижняя граница | Ω | "Не быстрее Ω(n)" |
| Точная оценка | Θ | "Ровно Θ(n log n)" |

## Как работает

### Проверка на Big Theta

Чтобы доказать f(n) = Θ(g(n)):
1. Показать f(n) = O(g(n)) — найти c₂
2. Показать f(n) = Ω(g(n)) — найти c₁

**Пример:** Доказать, что 3n² + 5n + 2 = Θ(n²)

```
Верхняя граница (Big O):
3n² + 5n + 2 ≤ 3n² + 5n² + 2n² = 10n²
→ c₂ = 10, работает при n ≥ 1

Нижняя граница (Big Ω):
3n² + 5n + 2 ≥ 3n²
→ c₁ = 3, работает при n ≥ 0

Итого: 3n² ≤ 3n² + 5n + 2 ≤ 10n²
→ 3n² + 5n + 2 = Θ(n²) ✓
```

### Свойства Big Theta

**Рефлексивность:**
```
f(n) = Θ(f(n))
```

**Симметричность:**
```
f(n) = Θ(g(n)) ⟺ g(n) = Θ(f(n))
```

**Транзитивность:**
```
f(n) = Θ(g(n)) и g(n) = Θ(h(n)) → f(n) = Θ(h(n))
```

## Визуализация

### Графическое представление Big Theta

```
f(n)
  ↑
  │            ╱ c₂·g(n) — верхняя граница
  │          ╱
  │        ╱  _____ f(n) — между границами
  │      ╱__-╱
  │    ╱-╱
  │  ╱╱    -------- c₁·g(n) — нижняя граница
  │╱╱   --╱
  │╱---╱
  └─────────────────────→ n
      ↑
      n₀

f(n) "зажата" между c₁·g(n) и c₂·g(n)
```

### "Сэндвич" Big Theta

```
     c₂ · g(n)
  ═══════════════  ← верхний хлеб (Big O)

     f(n)
  ───────────────  ← начинка (наша функция)

     c₁ · g(n)
  ═══════════════  ← нижний хлеб (Big Ω)
```

## Примеры с разбором

### Пример 1: Простой проход по массиву

```python
def sum_array(arr):
    total = 0
    for x in arr:
        total += x
    return total
```

**Анализ:**
- Всегда выполняется n итераций
- Best case = Worst case = n операций
- **Θ(n)** — точная оценка

### Пример 2: Сортировка слиянием

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr

    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)
```

**Анализ:**
- Всегда делит массив пополам (log n уровней)
- На каждом уровне O(n) операций слияния
- Best case = Worst case = n log n
- **Θ(n log n)** — точная оценка

### Пример 3: Бинарный поиск

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1

    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1

    return -1
```

**Анализ:**
- Best case: O(1) — элемент в середине
- Worst case: O(log n) — элемент в конце
- Best ≠ Worst, поэтому **нельзя использовать Θ для алгоритма в целом**
- Но можно сказать: Worst case = Θ(log n)

### Пример 4: Когда Θ НЕ применимо

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr

    pivot = arr[0]
    less = [x for x in arr[1:] if x <= pivot]
    greater = [x for x in arr[1:] if x > pivot]

    return quick_sort(less) + [pivot] + quick_sort(greater)
```

**Анализ:**
- Best case: Ω(n log n) — сбалансированные разбиения
- Worst case: O(n²) — уже отсортированный массив
- Big O ≠ Big Ω, поэтому **Θ не определено**

### Пример 5: Математические функции

```
f(n) = 5n³ + 3n² + 7n + 10

Big O:  O(n³)  — растёт не быстрее n³
Big Ω:  Ω(n³)  — растёт не медленнее n³
Big Θ:  Θ(n³)  — растёт как n³

Доказательство:
- 5n³ ≤ 5n³ + 3n² + 7n + 10 ≤ 5n³ + 3n³ + 7n³ + 10n³ = 25n³
- c₁ = 5, c₂ = 25, n₀ = 1
```

## Сравнительная таблица

| Алгоритм | Best | Worst | Θ определено? |
|----------|------|-------|---------------|
| Поиск максимума | Ω(n) | O(n) | Да: Θ(n) |
| Сортировка слиянием | Ω(n log n) | O(n log n) | Да: Θ(n log n) |
| Быстрая сортировка | Ω(n log n) | O(n²) | Нет |
| Линейный поиск | Ω(1) | O(n) | Нет |
| Вставка в хеш-таблицу | Ω(1) | O(n) | Нет |
| Вставка в конец массива | Ω(1) | O(1) | Да: Θ(1)* |

*амортизированно

## Типичные ошибки

### 1. Использовать Θ когда Best ≠ Worst

```python
# НЕПРАВИЛЬНО говорить "линейный поиск — Θ(n)"
# Best case = O(1), Worst case = O(n)
# Θ не определено!

# ПРАВИЛЬНО:
# - "Worst case линейного поиска — Θ(n)"
# - "Линейный поиск — O(n)"
```

### 2. Путать Θ с O

```
# Big O даёт только верхнюю границу:
n = O(n²)     — правда (n растёт не быстрее n²)
n = O(n)      — правда
n = O(2ⁿ)    — правда

# Big Θ требует точного соответствия:
n = Θ(n²)    — ЛОЖЬ (n растёт медленнее n²)
n = Θ(n)     — правда
n = Θ(2ⁿ)   — ЛОЖЬ
```

### 3. Забывать про константы в анализе

```python
# Оба алгоритма Θ(n), но один быстрее:
def algo1(arr):
    for x in arr:
        process(x)  # 1 операция

def algo2(arr):
    for x in arr:
        for _ in range(100):  # 100 операций
            process(x)

# algo1: ~n операций
# algo2: ~100n операций
# Оба Θ(n), но algo2 в 100 раз медленнее!
```

### 4. Неправильно применять к сложным случаям

```python
# Амортизированный анализ
arr = []
for i in range(n):
    arr.append(i)

# Каждый append — O(1) амортизированно
# Но иногда O(n) при расширении
# Говорим: "Θ(1) амортизированно"
```

## Практическое использование

### Когда важно различать нотации

```python
# Если нужна гарантия:
# → Используй Big O (худший случай)

# Если нужно сравнить алгоритмы:
# → Используй Big Θ (если определено)

# Если доказываешь оптимальность:
# → Используй Big Ω (нижняя граница)
```

### Типичные Θ для алгоритмов

| Операция | Θ |
|----------|---|
| Доступ к массиву по индексу | Θ(1) |
| Поиск min/max в массиве | Θ(n) |
| Сортировка слиянием | Θ(n log n) |
| Умножение матриц (наивное) | Θ(n³) |
| Обход всех пар | Θ(n²) |

## Резюме

- Big Theta описывает **точную** асимптотическую сложность
- Θ(g(n)) означает, что f(n) = O(g(n)) **И** f(n) = Ω(g(n))
- Используется когда best case = worst case (по порядку роста)
- Если best ≠ worst, Θ не определено для алгоритма в целом
- Θ позволяет сравнивать алгоритмы по их истинной сложности
- В разговорной речи часто O используют вместо Θ (но это неточно)

---

[prev: 03-big-omega](./03-big-omega.md) | [next: 05-common-complexities](./05-common-complexities.md)
